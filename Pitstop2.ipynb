{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Pitstop2.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YV07HtF4RJf"
      },
      "source": [
        "#define _FILE_SPECS \"-rw-r--r-- 1 chris 8007 Mar 25 12:33 cartsim_data.py\"\n",
        "#define _MAGIC_NUMBER 1147484068\n",
        "import numpy as np\n",
        "import math, os,   sys,  time\n",
        "from time import gmtime, strftime\n",
        "# from logger import logger\n",
        "from datetime import date, datetime, timezone\n",
        "import statistics as st\n",
        "import random as rn\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import random as rnn\n",
        " \n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "\n",
        "#equations\n",
        "# M \\ddot P = - C( X - X_0)  - D \\dot X\n",
        "#  P = X  + Z(Y(t))\n",
        "#  Y(t)= vt\n",
        "\n",
        "#  v=60km/hour = 16.666 m / sec\n",
        "#\n",
        "#  M= 1000kg\n",
        "#  X_0 =  5cm\n",
        "#  C spring const so 1000kg @ 10 m/sec^2 gives 5 cm ie\n",
        "#    =   5 x 10e-06\n",
        "#  X roughly +- 10cm\n",
        "#  road 3 components period   1 sec, 2 sec, 4 sec (random amplitude)\n",
        "#  sin(Y/(16.666)),  cos(Y/(16.666)), sin(Y/(2*16.66)), cos(Y/(2*16.66))\n",
        "#  choose D0 to efold in 1 second ie. D/2M = 1.0 --> D=2000\n",
        "#  too small is 'bad'\n",
        "#  choose sampling rate @ 4 Hz\n",
        "#  magnitude road = +- 5 max * sin( Y / 16.66 m)\n",
        "\n",
        "#  10 minute samples = 600 x 4 points @ 4 Hz\n",
        "#\n",
        "\n",
        "def Zbase ( trigtype, period, K, Y):\n",
        "    \n",
        "    if trigtype=='sin':\n",
        "        return math.sin( K * period * Y)\n",
        "    if trigtype=='cos':\n",
        "        return math.cos( K * period * Y)\n",
        "    \n",
        "def Zbaseddot ( trigtype, period, K, Y, v):\n",
        "    \n",
        "#     d^2/dt^ (VT)=0\n",
        "    if trigtype=='sin':\n",
        "        return -math.cos( K * period * Y) * v * v * (K /period) * (K/period)\n",
        "    if trigtype=='cos':\n",
        "        return -math.sin( K * period * Y) * v * v * (K /period) * (K/period)\n",
        "    \n",
        "def Xdot(Xn, Xnm1, dT):\n",
        "    return (Xn - Xnm1)/dT\n",
        "\n",
        "def Xddot(Xn, Xnm1, Xnm2, dT):\n",
        "    return (Xn - 2 * Xnm1  + Xnm2)/(dT * dT)\n",
        "\n",
        "def getXnp1(LHS, M, D, C, Xn, Xnm1, dT):\n",
        "# solve for Xnp1\n",
        "#  LHS = M(Xnp1 - 2 Xn + Xnm1)/delT^2 + D(Xnp1 - Xnm1)/2delT + C Xn\n",
        "  \n",
        "    rval = (LHS * dT * dT - (M - D * dT/2) * Xnm1  + (2 *M - C * dT * dT) * Xn  )/(M + D * dT/2) \n",
        "    \n",
        "    lv = M* (rval - 2 * Xn + Xnm1)/(dT * dT) + D* (rval - Xnm1)/(2*dT) + C * Xn\n",
        "    \n",
        "#    print(\"check %f = %f\" % (LHS,lv))\n",
        "          \n",
        "    return  rval\n",
        "\n",
        "def getLHSval(Zddval, Ms, Vs, Cs, X0s):\n",
        "# Cs * X0 =spring force\n",
        "    return - Ms * Zddval + Cs * X0s\n",
        "\n",
        "def zRoad(coeffs, v, Y, period, maxfreq):\n",
        "    \n",
        "    zR =0\n",
        "   \n",
        "    if maxfreq >= 0.5:\n",
        "       zR = coeffs[0]* Zbaseddot('cos', period, 0.5, Y, v) + zR\n",
        "       zR = coeffs[1]* Zbaseddot('sin', period, 0.5, Y, v) + zR\n",
        "\n",
        "    if maxfreq >= 1.0:\n",
        "       zR = coeffs[2]* Zbaseddot('cos', period, 1.0, Y, v) + zR\n",
        "       zR = coeffs[3]* Zbaseddot('sin', period, 1.0, Y, v) + zR\n",
        "    \n",
        "    if maxfreq >=2.0:\n",
        "       zR = coeffs[4]* Zbaseddot('cos', period, 2.0, Y, v) + zR\n",
        "       zR = coeffs[5]* Zbaseddot('sin', period, 2.0, Y, v) + zR\n",
        "       \n",
        "    if maxfreq >=4.0:\n",
        "       zR = coeffs[6]* Zbaseddot('cos', period, 4.0, Y, v) + zR\n",
        "       zR = coeffs[7]* Zbaseddot('sin', period, 4.0, Y, v) + zR\n",
        "    \n",
        "    return zR\n",
        "\n",
        "def  getRandomCoeffs(N):\n",
        "    \n",
        "     ampChoice=[0.01, 0.02, 0.025, 0.03, 0.035]\n",
        "     coeffs=[]\n",
        "\n",
        "     for i in range(0,N):\n",
        "          rAmpl1=rn.choice(ampChoice) \n",
        "#          rAmpl1=rAmpl\n",
        "          coeffs.append(rAmpl1)\n",
        "          \n",
        "     return coeffs\n",
        " \n",
        " \n",
        "\n",
        "def  compute_sim(M, D0, V, C, X0, delT, period, maxfreq, coeffs, topsample):\n",
        "    \n",
        "    Y=0\n",
        "# start with spring at rest\n",
        "    Xnp1=X0\n",
        "    Xn=X0\n",
        "    Xnm1=X0\n",
        "\n",
        "\n",
        "    springPos=[]\n",
        "    timeVal=[]\n",
        "    roadSurf=[]\n",
        "    \n",
        "     \n",
        "    for i in range(0, topsample):\n",
        "    \n",
        "        t= i * delT\n",
        "        timeVal.append(t)\n",
        "#        print(\"                T=%8.2f\" % t)\n",
        "    \n",
        "        Y= V * t  \n",
        "    \n",
        "        Zddval= zRoad(coeffs, V, Y, period, maxfreq)\n",
        "    \n",
        "#        print(\"Zddval %f\" % Zddval)\n",
        "    \n",
        "# LHS= -M (ddot (Z(Y))) + CX0\n",
        "        LHS= getLHSval(Zddval, M, V, C, X0)\n",
        "        roadSurf.append(LHS)\n",
        "    \n",
        "        Xnp1 = getXnp1(LHS, M, D0, C, Xn, Xnm1, delT)\n",
        "        springPos.append(Xnp1)\n",
        "    \n",
        "#        print(\"Xnp1 %8.3f  Xn %8.3f Xnm1 %8.3f\" % (Xnp1, Xn, Xnm1))\n",
        "    \n",
        "        Xnm1=Xn\n",
        "        Xn=Xnp1\n",
        "        \n",
        "    return [roadSurf, timeVal, springPos, t]\n",
        "\n",
        "def add_sample(M, D0, V, C, X0, delT, period, maxfreq, botsample, topsample, lval,Ncoeffs, Rcoeffs, road_input_type):\n",
        " # compute discriminant\n",
        "    disc= D0*D0 - 4 * M * C   \n",
        "    \n",
        "    [roadSurf, timeVals, springPos, tmax]= compute_sim(M, D0, V, C, X0, delT, period, maxfreq, Rcoeffs, topsample)\n",
        "\n",
        "    yval=[]\n",
        "    Xdat=[]\n",
        "\n",
        "#    print(\"sample D0=%d label=%s\" % (D0,lval )) \n",
        "#    print(\"D=%12.2f disc  %12.2f   maxfreq= %f\" % (D0, disc,   maxfreq))\n",
        "#    if disc < 0:\n",
        "#        print(\"sqrt = %f\" % math.sqrt(-disc))\n",
        " \n",
        "# assume botsample is > 3\n",
        "\n",
        "    if road_input_type=='vibration':\n",
        "        tupleLen=8\n",
        "    elif road_input_type=='surface':\n",
        "        tupleLen=2\n",
        "    else:\n",
        "        print(\"unknown road_type %s\" % road_type)\n",
        "        tupleLen=2\n",
        " \n",
        "# in this case include roadSurf = LHS as variable\n",
        "    xnorm=10000 \n",
        "    for i in range(botsample,topsample):\n",
        "        if tupleLen==2:\n",
        "# road input\n",
        "           Xdat.append([roadSurf[i]/xnorm, springPos[i-2], springPos[i-1], springPos[i]])\n",
        "# in vehicle vibration\n",
        "        elif tupleLen==5:\n",
        "           Xdat.append([springPos[i-5], springPos[i-4], springPos[i-3], springPos[i-2], springPos[i-1], springPos[i]])\n",
        "#  in vehicle vibration (long)\n",
        "        elif tupleLen==8:\n",
        "           Xdat.append([springPos[-8], springPos[-7], springPos[-6], springPos[i-5], springPos[i-4], springPos[i-3], springPos[i-2], springPos[i-1], springPos[i]])\n",
        "        else:\n",
        "            print(\"Unsupported tupleLen %d\" % tupleLen)\n",
        "            return [[],[]]\n",
        "        \n",
        "        yval.append(lval)\n",
        " \n",
        "    return [Xdat, yval]\n",
        "\n",
        "# This main function generates data based on user's selection of parameters    \n",
        "def generate_data(number_runs, experiment_type, observation_type):\n",
        "\n",
        "  # mass    \n",
        "  M=2000 \n",
        "  #   5cm compression\n",
        "  X0= 0.05\n",
        "  # spring const    \n",
        "\n",
        "  C= 0.6  * 10e+04\n",
        "  delT=0.25\n",
        "  # interesting values 500, 5000, 15000, 25000\n",
        "  \n",
        "  # damping\n",
        "  Dvalues=[5000, 5500, 6000, 6500, 4500, 4000, 3500, 500, 600, 700, 800, 400, 300, 200]\n",
        "\n",
        "  LABELvalues=['good','good', 'good', 'good', 'good','good','good','bad','bad','bad','bad','bad','bad','bad']\n",
        "\n",
        "  dindexlist=[x for x in range(0,14)]\n",
        "\n",
        "  \n",
        "  # car moves at 16.66 m/s\n",
        "  V= 16.66 \n",
        "  period= 16.66 \n",
        "  maxfreq=4.0\n",
        "  \n",
        "  botsample=400 \n",
        "  topsample=500\n",
        "  Ncoeffs=8\n",
        "\n",
        "  X=[]\n",
        "  y=[]\n",
        "  ngood=0\n",
        "  nbad=0\n",
        "\n",
        "  nruns = number_runs or 500\n",
        "  experiment_type= experiment_type or 'random_roads'\n",
        "  # experiment_type='standard_road'\n",
        "\n",
        "  # initialize road\n",
        "  Rcoeffs=getRandomCoeffs(Ncoeffs) \n",
        "\n",
        "  ldindexlist=[x for x in range(0, 100* nruns)]\n",
        "\n",
        "  for i in range(0,nruns):\n",
        "      \n",
        "            dindex=rn.choice(dindexlist)\n",
        "\n",
        "            D0=Dvalues[dindex]\n",
        "            labval=LABELvalues[dindex]\n",
        "      \n",
        "  \n",
        "            if experiment_type=='random_roads':\n",
        "                Rcoeffs=getRandomCoeffs(Ncoeffs)\n",
        "                \n",
        "\n",
        "  \n",
        "  #  For  in vehicle vibration road_input_type='vibration'\n",
        "  #  For  road input set road_input_type='surface'\n",
        "            \n",
        "            road_input_type = observation_type or 'surface'\n",
        "            #  road_input_type='vibration'\n",
        "  \n",
        "            [Xdat, yval]= add_sample(M, D0, V, C, X0, delT, period, maxfreq, botsample, topsample, labval,Ncoeffs, Rcoeffs, road_input_type)\n",
        "            \n",
        "  # [roadsurf, Xn-2, Xn-1, Xn]\n",
        "            if yval[0]=='good':\n",
        "                ngood+=1\n",
        "            if yval[0]=='bad':\n",
        "                nbad+=1\n",
        "  \n",
        "            for j in range(0, len(Xdat)):\n",
        "                  X.append(Xdat[j])\n",
        "                  y.append(yval[j])\n",
        "                  \n",
        "\n",
        "  print(\"shuffling %d entries\" % len(ldindexlist))\n",
        "  rn.shuffle(ldindexlist)\n",
        "  # sanity check\n",
        "  print(ldindexlist[0:10])\n",
        "\n",
        "  X_rn=[]\n",
        "  y_rn=[]\n",
        "\n",
        "  for i in range(0, len(X)):\n",
        "      X_rn.append(X[ldindexlist[i]])\n",
        "      y_rn.append(y[ldindexlist[i]])\n",
        "      \n",
        "      \n",
        "            \n",
        "  print(\"made %d samples with botsample %d topsample %d\" % (nruns,botsample, topsample))\n",
        "  print(\"maxfreq= %8.2f M= %8.2f V=%8.2f C=%8.2f\" % (maxfreq, M, V, C))\n",
        "\n",
        "  totalN=len(X)\n",
        "  print(\"Total samples %d good runs %d bad runs %d\" % (totalN, ngood, nbad))\n",
        "\n",
        "  #print(Xdat)\n",
        "\n",
        "  print (strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "\n",
        "  return X_rn, y_rn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lhBJiYa1V3h"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAPMBWUBqhyd"
      },
      "source": [
        "The confusion matrix is a common metric to measure the performance of a classification algorithm. In this case, only \"good\" and \"bad\" are labelled (binary). So the confusion matrix can be shown as below:\n",
        "\n",
        "|               | Predicted(No) | Predicted(Yes)  |\n",
        "| ------------- |:---------------:| -----------------:|\n",
        "| **Actual(No)**   | True Negatives (TN) | False Positives (FP) |\n",
        "| **Actual(Yes)**  | False Negatives (FN) | True Positives (TP) |\n",
        "\n",
        "From the matrix, we could get the Accuracy by this formula:\n",
        "$$ Accuracy = \\frac {TP + TN}{TP + TN + FP + FN} $$\n",
        "\n",
        "And the Error rate would be $1-Accuracy$, same as\n",
        "$$ ErrorRate = \\frac {FP + FN}{TP + TN + FP + FN} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfJZFK8P6bsd"
      },
      "source": [
        "## Model Selection\n",
        "----\n",
        "\n",
        "Here is the summary table of all model candidates ranked by the Accuracy.\n",
        "\n",
        "|Model|Accuracy|AUC|Recall|Prec.|F1|Kappa|MCC|TT (Sec)|\n",
        "|--- |--- |--- |--- |--- |--- |--- |--- |--- |\n",
        "|Extra Trees Classifier|0.9791|0.9983|0.9789|0.9806|0.9797|0.9582|0.9582|1.709|\n",
        "|Quadratic Discriminant Analysis|0.9783|0.9998|0.9579|1.0000|0.9785|0.9566|0.9576|0.036|\n",
        "|K Neighbors Classifier|0.9729|0.9955|0.9731|0.9742|0.9736|0.9457|0.9457|0.213|\n",
        "|Random Forest Classifier|0.9727|0.9969|0.9710|0.9759|0.9735|0.9454|0.9455|7.500|\n",
        "|Decision Tree Classifier|0.9477|0.9477|0.9472|0.9510|0.9491|0.8953|0.8953|0.244|\n",
        "|Light Gradient Boosting Machine|0.9339|0.9893|0.9651|0.9118|0.9376|0.8674|0.8691|0.360|\n",
        "|Gradient Boosting Classifier|0.8409|0.9444|0.9266|0.7973|0.8570|0.6799|0.6898|4.073|\n",
        "|Ada Boost Classifier|0.6967|0.7706|0.8287|0.6648|0.7377|0.3883|0.4018|1.082|\n",
        "|Naive Bayes|0.6476|0.6815|0.7716|0.6284|0.6926|0.2898|0.2983|0.032|\n",
        "|Linear Discriminant Analysis|0.5494|0.5109|0.9391|0.5356|0.6820|0.0768|0.1267|0.049|\n",
        "|Ridge Classifier|0.5278|0.0000|0.9967|0.5217|0.6849|0.0279|0.0915|0.031|\n",
        "|Logistic Regression|0.5148|0.5109|1.0000|0.5148|0.6797|0.0003|0.0039|0.379|\n",
        "|SVM - Linear Kernel|0.5147|0.0000|1.0000|0.5147|0.6796|0.0000|0.0000|0.062|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1XQJHld6iQW"
      },
      "source": [
        "Tree models and KNN have very good accuracy compared to other models. However, most of tree classifiers need more time to compute (takes seconds). Therefore, I chose the common **KNN model** as the estimator in this case, which has a pretty good Accuracy and AUC as well as short training time (0.213s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khXusr_hwnU0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSylfLynFt8g"
      },
      "source": [
        "## Define Function for Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2U5I0OopZ-q"
      },
      "source": [
        "# Create a function to generate model result\n",
        "def ml_result_report(y_test, y_pred):\n",
        "  # Create Confusion Matrix with testing and prediction data\n",
        "  Mc = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  totalN = Mc[0][0] + Mc[0][1] + Mc[1][0] + Mc[1][1]\n",
        "  misclassifiedN = Mc[0][1] + Mc[1][0]\n",
        "\n",
        "  errorRate = misclassifiedN / totalN\n",
        "\n",
        "  print(\"confusion matrix: on test data set\")\n",
        "  print(Mc)\n",
        "\n",
        "  print(\"errorRate %5.3f\" % errorRate)\n",
        "  # print (strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "  print(\"N=%d : experiment_type: %s  road_input_type: %s\" % (number_runs, experiment_type, observation_type))\n",
        "\n",
        "  return errorRate"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY3edCGrF45i"
      },
      "source": [
        "## Define a Model Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EFUs3zj152o"
      },
      "source": [
        "# Create a pipeline to train model and then predict\n",
        "def model_pipeline(X_rn, y_rn, model):\n",
        "  # Split samples\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_rn, y_rn, test_size=testfraction, random_state=42)\n",
        "\n",
        "  # Standardization of sample\n",
        "  X_scaler = StandardScaler().fit(X_train)\n",
        "  X_train_scaled = X_scaler.transform(X_train)\n",
        "  X_test_scaled = X_scaler.transform(X_test)\n",
        "\n",
        "  # Train model\n",
        "  model.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # Print out score\n",
        "  train_score = model.score(X_train_scaled, y_train)\n",
        "  model_score = model.score(X_test_scaled, y_test)\n",
        "  print(\"Train score: %5.4f\" % train_score)\n",
        "  print(\"Model score: %5.4f\" % model_score)\n",
        "\n",
        "  # Get predict data\n",
        "  y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "  return y_test, y_pred"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGo0Rec1F8TI"
      },
      "source": [
        "## Define Main Function to Run 4 Replications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPZWTID3E88n"
      },
      "source": [
        "# A main function to generate avg error rate\n",
        "def compute_avg_err_rate(model):\n",
        "  \n",
        "  list_err_rate = []\n",
        "\n",
        "  # Main function to generate required data\n",
        "  for i in range(4):\n",
        "    X_rn, y_rn = generate_data(number_runs, experiment_type, observation_type)\n",
        "\n",
        "    y_test, y_pred = model_pipeline(X_rn, y_rn, knn)\n",
        "    err_rate = ml_result_report(y_test, y_pred)\n",
        "\n",
        "    list_err_rate.append(err_rate)\n",
        "    print(\"========== %s out of 4 replications========\" % (i+1))\n",
        "\n",
        "  print(\"The average error rate of 4 replications is:\")\n",
        "  print(sum(list_err_rate)/len(list_err_rate))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glroNK1BFhJ1"
      },
      "source": [
        "# Generate Data and Return result with 3 Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX2g3LGZJ2X6"
      },
      "source": [
        "## Parameter Settings for Each Case\n",
        "\n",
        "N runs, Experiment type, Observation type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPNp5dJw9V16"
      },
      "source": [
        "#====================================================\n",
        "# Here is the list of parameter variables\n",
        "# Change the following variable values for each case\n",
        "#----------------------------------------------------\n",
        "number_runs = 200\n",
        "# experiment_type = \"standard_road\"\n",
        "experiment_type = \"random_roads\"\n",
        "\n",
        "observation_type = \"surface\"\n",
        "# observation_type = \"vibration\"\n",
        "testfraction = 0.3\n",
        "#===================================================="
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtTd5_ykKDoX"
      },
      "source": [
        "## KNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k5MyPu74RKX",
        "outputId": "95d6c22f-9c13-413f-cb53-a1e9f67fa867"
      },
      "source": [
        "# KNN\n",
        "# A n_neighbors vs accuracy plotting was done separately\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "compute_avg_err_rate(knn)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shuffling 50000 entries\n",
            "[36867, 19471, 28194, 10806, 7384, 45232, 8538, 18767, 45858, 33489]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 276 bad runs 224\n",
            "2021-05-22 03:34:16\n",
            "Train score: 0.9919\n",
            "Model score: 0.9810\n",
            "confusion matrix: on test data set\n",
            "[[6557  172]\n",
            " [ 113 8158]]\n",
            "errorRate 0.019\n",
            "N=500 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 1 out of 4 replications========\n",
            "shuffling 50000 entries\n",
            "[26961, 14535, 40783, 11357, 960, 23015, 23381, 28512, 4891, 11422]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 245 bad runs 255\n",
            "2021-05-22 03:34:20\n",
            "Train score: 0.9917\n",
            "Model score: 0.9819\n",
            "confusion matrix: on test data set\n",
            "[[7595  135]\n",
            " [ 136 7134]]\n",
            "errorRate 0.018\n",
            "N=500 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 2 out of 4 replications========\n",
            "shuffling 50000 entries\n",
            "[47470, 9887, 39341, 23228, 20070, 33651, 45633, 12605, 20394, 9319]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 235 bad runs 265\n",
            "2021-05-22 03:34:24\n",
            "Train score: 0.9915\n",
            "Model score: 0.9809\n",
            "confusion matrix: on test data set\n",
            "[[7830  126]\n",
            " [ 160 6884]]\n",
            "errorRate 0.019\n",
            "N=500 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 3 out of 4 replications========\n",
            "shuffling 50000 entries\n",
            "[44107, 10659, 14686, 13563, 20574, 15656, 34654, 47319, 31487, 11567]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 250 bad runs 250\n",
            "2021-05-22 03:34:28\n",
            "Train score: 0.9915\n",
            "Model score: 0.9797\n",
            "confusion matrix: on test data set\n",
            "[[7411  159]\n",
            " [ 145 7285]]\n",
            "errorRate 0.020\n",
            "N=500 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 4 out of 4 replications========\n",
            "The average error rate of 4 replications is:\n",
            "0.0191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLf83g6ZKHL-"
      },
      "source": [
        "## Naive Bayes Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Q1J0RQ4RKb",
        "outputId": "a5ef35ba-08ef-43d4-cceb-8aface080a49"
      },
      "source": [
        "# NB\n",
        "nb = MultinomialNB()\n",
        "compute_avg_err_rate(nb)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shuffling 100000 entries\n",
            "[19517, 44713, 30003, 87982, 34762, 12576, 42558, 70632, 92770, 90467]\n",
            "made 1000 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 100000 good runs 501 bad runs 499\n",
            "2021-05-22 03:43:27\n",
            "Train score: 0.9937\n",
            "Model score: 0.9853\n",
            "confusion matrix: on test data set\n",
            "[[14715   195]\n",
            " [  247 14843]]\n",
            "errorRate 0.015\n",
            "N=1000 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 1 out of 4 replications========\n",
            "shuffling 100000 entries\n",
            "[32176, 47261, 78775, 93805, 34278, 97122, 31867, 12869, 74862, 42504]\n",
            "made 1000 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 100000 good runs 466 bad runs 534\n",
            "2021-05-22 03:43:35\n",
            "Train score: 0.9939\n",
            "Model score: 0.9858\n",
            "confusion matrix: on test data set\n",
            "[[15895   186]\n",
            " [  241 13678]]\n",
            "errorRate 0.014\n",
            "N=1000 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 2 out of 4 replications========\n",
            "shuffling 100000 entries\n",
            "[32047, 78310, 92075, 65259, 58778, 69893, 52113, 62482, 3243, 21077]\n",
            "made 1000 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 100000 good runs 501 bad runs 499\n",
            "2021-05-22 03:43:44\n",
            "Train score: 0.9945\n",
            "Model score: 0.9863\n",
            "confusion matrix: on test data set\n",
            "[[14786   202]\n",
            " [  209 14803]]\n",
            "errorRate 0.014\n",
            "N=1000 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 3 out of 4 replications========\n",
            "shuffling 100000 entries\n",
            "[84647, 20037, 48912, 80936, 8581, 13911, 12483, 4749, 74449, 75944]\n",
            "made 1000 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 100000 good runs 500 bad runs 500\n",
            "2021-05-22 03:43:52\n",
            "Train score: 0.9927\n",
            "Model score: 0.9846\n",
            "confusion matrix: on test data set\n",
            "[[14828   183]\n",
            " [  278 14711]]\n",
            "errorRate 0.015\n",
            "N=1000 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 4 out of 4 replications========\n",
            "The average error rate of 4 replications is:\n",
            "0.014508333333333335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blXHIrju4ctv"
      },
      "source": [
        "## Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJVz2eBXm0mJ"
      },
      "source": [
        "def nn_compute_avg_err_rate():\n",
        "\n",
        "  list_err_rate = []\n",
        "  # Main function to generate required data\n",
        "  for i in range(4):\n",
        "    X_rn, y_rn = generate_data(number_runs, experiment_type, observation_type)\n",
        "    \n",
        "    # Split samples\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_rn, y_rn, random_state=42)\n",
        "\n",
        "    # Standardization\n",
        "    X_scaler = StandardScaler().fit(X_train)\n",
        "    X_train_scaled = X_scaler.transform(X_train)\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "\n",
        "    # Transform y values\n",
        "    label_model = LabelEncoder()\n",
        "    label_model.fit(y_train)\n",
        "\n",
        "    y_train_encoded = label_model.transform(y_train)\n",
        "    y_test_encoded = label_model.transform(y_test)\n",
        "\n",
        "    # Convert to categorical data\n",
        "    y_train_categorical = to_categorical(y_train_encoded)\n",
        "    y_test_categorical = to_categorical(y_test_encoded)\n",
        "\n",
        "    # Building NN model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=4, activation=\"relu\", input_dim=4))\n",
        "    model.add(Dense(units=20, activation=\"relu\"))\n",
        "    model.add(Dense(units=5, activation=\"relu\"))\n",
        "    model.add(Dense(units=2, activation=\"softmax\"))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "    # Fitting model\n",
        "    model.fit(X_train_scaled, y_train_categorical, epochs=50, shuffle=True, verbose=2)\n",
        "\n",
        "    # Predit values\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_pred\n",
        "\n",
        "    # confusion_matrix(y_test_categorical.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "    err_rate = ml_result_report(y_test_categorical.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "\n",
        "    list_err_rate.append(err_rate)\n",
        "    print(\"========== %s out of 4 replications========\" % (i+1))\n",
        "\n",
        "  print(\"The average error rate of 4 replications is:\")\n",
        "  print(sum(list_err_rate)/len(list_err_rate))\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc_b3HwEM_8z",
        "outputId": "f52e5d21-3d23-4af8-b0d5-41de8fdadd77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Run MLP function\n",
        "nn_compute_avg_err_rate()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shuffling 20000 entries\n",
            "[17236, 10362, 12827, 18497, 5222, 15417, 10108, 201, 7670, 7508]\n",
            "made 200 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 20000 good runs 104 bad runs 96\n",
            "2021-05-22 03:54:03\n",
            "Epoch 1/50\n",
            "469/469 - 1s - loss: 0.6126 - accuracy: 0.6417\n",
            "Epoch 2/50\n",
            "469/469 - 0s - loss: 0.4229 - accuracy: 0.7761\n",
            "Epoch 3/50\n",
            "469/469 - 0s - loss: 0.1577 - accuracy: 0.9540\n",
            "Epoch 4/50\n",
            "469/469 - 0s - loss: 0.0817 - accuracy: 0.9735\n",
            "Epoch 5/50\n",
            "469/469 - 0s - loss: 0.0614 - accuracy: 0.9811\n",
            "Epoch 6/50\n",
            "469/469 - 0s - loss: 0.0510 - accuracy: 0.9827\n",
            "Epoch 7/50\n",
            "469/469 - 0s - loss: 0.0434 - accuracy: 0.9853\n",
            "Epoch 8/50\n",
            "469/469 - 0s - loss: 0.0383 - accuracy: 0.9881\n",
            "Epoch 9/50\n",
            "469/469 - 0s - loss: 0.0340 - accuracy: 0.9883\n",
            "Epoch 10/50\n",
            "469/469 - 0s - loss: 0.0312 - accuracy: 0.9893\n",
            "Epoch 11/50\n",
            "469/469 - 0s - loss: 0.0291 - accuracy: 0.9899\n",
            "Epoch 12/50\n",
            "469/469 - 0s - loss: 0.0263 - accuracy: 0.9902\n",
            "Epoch 13/50\n",
            "469/469 - 0s - loss: 0.0243 - accuracy: 0.9909\n",
            "Epoch 14/50\n",
            "469/469 - 0s - loss: 0.0236 - accuracy: 0.9911\n",
            "Epoch 15/50\n",
            "469/469 - 0s - loss: 0.0221 - accuracy: 0.9911\n",
            "Epoch 16/50\n",
            "469/469 - 0s - loss: 0.0217 - accuracy: 0.9911\n",
            "Epoch 17/50\n",
            "469/469 - 0s - loss: 0.0200 - accuracy: 0.9920\n",
            "Epoch 18/50\n",
            "469/469 - 0s - loss: 0.0185 - accuracy: 0.9929\n",
            "Epoch 19/50\n",
            "469/469 - 0s - loss: 0.0177 - accuracy: 0.9939\n",
            "Epoch 20/50\n",
            "469/469 - 0s - loss: 0.0161 - accuracy: 0.9942\n",
            "Epoch 21/50\n",
            "469/469 - 0s - loss: 0.0176 - accuracy: 0.9922\n",
            "Epoch 22/50\n",
            "469/469 - 0s - loss: 0.0172 - accuracy: 0.9921\n",
            "Epoch 23/50\n",
            "469/469 - 0s - loss: 0.0142 - accuracy: 0.9943\n",
            "Epoch 24/50\n",
            "469/469 - 0s - loss: 0.0133 - accuracy: 0.9958\n",
            "Epoch 25/50\n",
            "469/469 - 0s - loss: 0.0137 - accuracy: 0.9945\n",
            "Epoch 26/50\n",
            "469/469 - 0s - loss: 0.0138 - accuracy: 0.9943\n",
            "Epoch 27/50\n",
            "469/469 - 0s - loss: 0.0132 - accuracy: 0.9949\n",
            "Epoch 28/50\n",
            "469/469 - 0s - loss: 0.0141 - accuracy: 0.9941\n",
            "Epoch 29/50\n",
            "469/469 - 0s - loss: 0.0121 - accuracy: 0.9954\n",
            "Epoch 30/50\n",
            "469/469 - 0s - loss: 0.0117 - accuracy: 0.9959\n",
            "Epoch 31/50\n",
            "469/469 - 0s - loss: 0.0135 - accuracy: 0.9941\n",
            "Epoch 32/50\n",
            "469/469 - 0s - loss: 0.0127 - accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "469/469 - 0s - loss: 0.0116 - accuracy: 0.9958\n",
            "Epoch 34/50\n",
            "469/469 - 0s - loss: 0.0113 - accuracy: 0.9950\n",
            "Epoch 35/50\n",
            "469/469 - 0s - loss: 0.0151 - accuracy: 0.9937\n",
            "Epoch 36/50\n",
            "469/469 - 0s - loss: 0.0132 - accuracy: 0.9944\n",
            "Epoch 37/50\n",
            "469/469 - 0s - loss: 0.0138 - accuracy: 0.9941\n",
            "Epoch 38/50\n",
            "469/469 - 0s - loss: 0.0105 - accuracy: 0.9959\n",
            "Epoch 39/50\n",
            "469/469 - 0s - loss: 0.0103 - accuracy: 0.9961\n",
            "Epoch 40/50\n",
            "469/469 - 0s - loss: 0.0127 - accuracy: 0.9943\n",
            "Epoch 41/50\n",
            "469/469 - 0s - loss: 0.0148 - accuracy: 0.9939\n",
            "Epoch 42/50\n",
            "469/469 - 0s - loss: 0.0105 - accuracy: 0.9955\n",
            "Epoch 43/50\n",
            "469/469 - 0s - loss: 0.0112 - accuracy: 0.9955\n",
            "Epoch 44/50\n",
            "469/469 - 0s - loss: 0.0140 - accuracy: 0.9943\n",
            "Epoch 45/50\n",
            "469/469 - 0s - loss: 0.0100 - accuracy: 0.9957\n",
            "Epoch 46/50\n",
            "469/469 - 0s - loss: 0.0111 - accuracy: 0.9957\n",
            "Epoch 47/50\n",
            "469/469 - 0s - loss: 0.0110 - accuracy: 0.9954\n",
            "Epoch 48/50\n",
            "469/469 - 0s - loss: 0.0103 - accuracy: 0.9957\n",
            "Epoch 49/50\n",
            "469/469 - 0s - loss: 0.0106 - accuracy: 0.9953\n",
            "Epoch 50/50\n",
            "469/469 - 0s - loss: 0.0113 - accuracy: 0.9954\n",
            "confusion matrix: on test data set\n",
            "[[2412    2]\n",
            " [  14 2572]]\n",
            "errorRate 0.003\n",
            "N=200 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 1 out of 4 replications========\n",
            "shuffling 20000 entries\n",
            "[3492, 10070, 13762, 13549, 15428, 18303, 2755, 8622, 7384, 10842]\n",
            "made 200 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 20000 good runs 101 bad runs 99\n",
            "2021-05-22 03:54:26\n",
            "Epoch 1/50\n",
            "469/469 - 1s - loss: 0.6139 - accuracy: 0.6725\n",
            "Epoch 2/50\n",
            "469/469 - 0s - loss: 0.2658 - accuracy: 0.9387\n",
            "Epoch 3/50\n",
            "469/469 - 0s - loss: 0.1527 - accuracy: 0.9604\n",
            "Epoch 4/50\n",
            "469/469 - 0s - loss: 0.1143 - accuracy: 0.9685\n",
            "Epoch 5/50\n",
            "469/469 - 0s - loss: 0.0923 - accuracy: 0.9722\n",
            "Epoch 6/50\n",
            "469/469 - 0s - loss: 0.0788 - accuracy: 0.9748\n",
            "Epoch 7/50\n",
            "469/469 - 0s - loss: 0.0682 - accuracy: 0.9769\n",
            "Epoch 8/50\n",
            "469/469 - 0s - loss: 0.0603 - accuracy: 0.9790\n",
            "Epoch 9/50\n",
            "469/469 - 0s - loss: 0.0535 - accuracy: 0.9807\n",
            "Epoch 10/50\n",
            "469/469 - 0s - loss: 0.0480 - accuracy: 0.9830\n",
            "Epoch 11/50\n",
            "469/469 - 0s - loss: 0.0441 - accuracy: 0.9834\n",
            "Epoch 12/50\n",
            "469/469 - 0s - loss: 0.0394 - accuracy: 0.9849\n",
            "Epoch 13/50\n",
            "469/469 - 0s - loss: 0.0353 - accuracy: 0.9871\n",
            "Epoch 14/50\n",
            "469/469 - 0s - loss: 0.0330 - accuracy: 0.9879\n",
            "Epoch 15/50\n",
            "469/469 - 0s - loss: 0.0300 - accuracy: 0.9888\n",
            "Epoch 16/50\n",
            "469/469 - 0s - loss: 0.0292 - accuracy: 0.9893\n",
            "Epoch 17/50\n",
            "469/469 - 0s - loss: 0.0274 - accuracy: 0.9896\n",
            "Epoch 18/50\n",
            "469/469 - 0s - loss: 0.0264 - accuracy: 0.9895\n",
            "Epoch 19/50\n",
            "469/469 - 0s - loss: 0.0255 - accuracy: 0.9897\n",
            "Epoch 20/50\n",
            "469/469 - 0s - loss: 0.0241 - accuracy: 0.9903\n",
            "Epoch 21/50\n",
            "469/469 - 0s - loss: 0.0229 - accuracy: 0.9911\n",
            "Epoch 22/50\n",
            "469/469 - 0s - loss: 0.0232 - accuracy: 0.9911\n",
            "Epoch 23/50\n",
            "469/469 - 0s - loss: 0.0215 - accuracy: 0.9911\n",
            "Epoch 24/50\n",
            "469/469 - 0s - loss: 0.0205 - accuracy: 0.9909\n",
            "Epoch 25/50\n",
            "469/469 - 0s - loss: 0.0193 - accuracy: 0.9919\n",
            "Epoch 26/50\n",
            "469/469 - 0s - loss: 0.0184 - accuracy: 0.9926\n",
            "Epoch 27/50\n",
            "469/469 - 0s - loss: 0.0190 - accuracy: 0.9923\n",
            "Epoch 28/50\n",
            "469/469 - 0s - loss: 0.0183 - accuracy: 0.9929\n",
            "Epoch 29/50\n",
            "469/469 - 0s - loss: 0.0166 - accuracy: 0.9936\n",
            "Epoch 30/50\n",
            "469/469 - 0s - loss: 0.0196 - accuracy: 0.9914\n",
            "Epoch 31/50\n",
            "469/469 - 0s - loss: 0.0169 - accuracy: 0.9931\n",
            "Epoch 32/50\n",
            "469/469 - 0s - loss: 0.0166 - accuracy: 0.9940\n",
            "Epoch 33/50\n",
            "469/469 - 0s - loss: 0.0167 - accuracy: 0.9931\n",
            "Epoch 34/50\n",
            "469/469 - 0s - loss: 0.0154 - accuracy: 0.9936\n",
            "Epoch 35/50\n",
            "469/469 - 0s - loss: 0.0164 - accuracy: 0.9931\n",
            "Epoch 36/50\n",
            "469/469 - 0s - loss: 0.0157 - accuracy: 0.9934\n",
            "Epoch 37/50\n",
            "469/469 - 0s - loss: 0.0157 - accuracy: 0.9929\n",
            "Epoch 38/50\n",
            "469/469 - 0s - loss: 0.0149 - accuracy: 0.9941\n",
            "Epoch 39/50\n",
            "469/469 - 0s - loss: 0.0150 - accuracy: 0.9943\n",
            "Epoch 40/50\n",
            "469/469 - 0s - loss: 0.0148 - accuracy: 0.9938\n",
            "Epoch 41/50\n",
            "469/469 - 0s - loss: 0.0140 - accuracy: 0.9943\n",
            "Epoch 42/50\n",
            "469/469 - 0s - loss: 0.0145 - accuracy: 0.9938\n",
            "Epoch 43/50\n",
            "469/469 - 0s - loss: 0.0142 - accuracy: 0.9938\n",
            "Epoch 44/50\n",
            "469/469 - 0s - loss: 0.0136 - accuracy: 0.9944\n",
            "Epoch 45/50\n",
            "469/469 - 0s - loss: 0.0127 - accuracy: 0.9947\n",
            "Epoch 46/50\n",
            "469/469 - 0s - loss: 0.0149 - accuracy: 0.9931\n",
            "Epoch 47/50\n",
            "469/469 - 0s - loss: 0.0134 - accuracy: 0.9940\n",
            "Epoch 48/50\n",
            "469/469 - 0s - loss: 0.0143 - accuracy: 0.9939\n",
            "Epoch 49/50\n",
            "469/469 - 0s - loss: 0.0150 - accuracy: 0.9929\n",
            "Epoch 50/50\n",
            "469/469 - 0s - loss: 0.0124 - accuracy: 0.9950\n",
            "confusion matrix: on test data set\n",
            "[[2452   19]\n",
            " [  12 2517]]\n",
            "errorRate 0.006\n",
            "N=200 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 2 out of 4 replications========\n",
            "shuffling 20000 entries\n",
            "[8652, 16749, 5268, 11229, 8816, 8265, 16760, 8250, 19159, 11607]\n",
            "made 200 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 20000 good runs 107 bad runs 93\n",
            "2021-05-22 03:54:48\n",
            "Epoch 1/50\n",
            "469/469 - 1s - loss: 0.6489 - accuracy: 0.6550\n",
            "Epoch 2/50\n",
            "469/469 - 0s - loss: 0.4598 - accuracy: 0.7547\n",
            "Epoch 3/50\n",
            "469/469 - 0s - loss: 0.3892 - accuracy: 0.7813\n",
            "Epoch 4/50\n",
            "469/469 - 0s - loss: 0.3297 - accuracy: 0.8625\n",
            "Epoch 5/50\n",
            "469/469 - 0s - loss: 0.2600 - accuracy: 0.9055\n",
            "Epoch 6/50\n",
            "469/469 - 0s - loss: 0.1715 - accuracy: 0.9270\n",
            "Epoch 7/50\n",
            "469/469 - 0s - loss: 0.1134 - accuracy: 0.9501\n",
            "Epoch 8/50\n",
            "469/469 - 0s - loss: 0.0950 - accuracy: 0.9555\n",
            "Epoch 9/50\n",
            "469/469 - 0s - loss: 0.0847 - accuracy: 0.9589\n",
            "Epoch 10/50\n",
            "469/469 - 0s - loss: 0.0773 - accuracy: 0.9639\n",
            "Epoch 11/50\n",
            "469/469 - 0s - loss: 0.0718 - accuracy: 0.9657\n",
            "Epoch 12/50\n",
            "469/469 - 0s - loss: 0.0667 - accuracy: 0.9677\n",
            "Epoch 13/50\n",
            "469/469 - 0s - loss: 0.0628 - accuracy: 0.9718\n",
            "Epoch 14/50\n",
            "469/469 - 0s - loss: 0.0593 - accuracy: 0.9701\n",
            "Epoch 15/50\n",
            "469/469 - 0s - loss: 0.0545 - accuracy: 0.9744\n",
            "Epoch 16/50\n",
            "469/469 - 0s - loss: 0.0519 - accuracy: 0.9743\n",
            "Epoch 17/50\n",
            "469/469 - 0s - loss: 0.0470 - accuracy: 0.9771\n",
            "Epoch 18/50\n",
            "469/469 - 0s - loss: 0.0448 - accuracy: 0.9783\n",
            "Epoch 19/50\n",
            "469/469 - 0s - loss: 0.0419 - accuracy: 0.9803\n",
            "Epoch 20/50\n",
            "469/469 - 0s - loss: 0.0402 - accuracy: 0.9795\n",
            "Epoch 21/50\n",
            "469/469 - 0s - loss: 0.0366 - accuracy: 0.9825\n",
            "Epoch 22/50\n",
            "469/469 - 0s - loss: 0.0348 - accuracy: 0.9834\n",
            "Epoch 23/50\n",
            "469/469 - 0s - loss: 0.0330 - accuracy: 0.9848\n",
            "Epoch 24/50\n",
            "469/469 - 0s - loss: 0.0294 - accuracy: 0.9869\n",
            "Epoch 25/50\n",
            "469/469 - 0s - loss: 0.0285 - accuracy: 0.9873\n",
            "Epoch 26/50\n",
            "469/469 - 0s - loss: 0.0264 - accuracy: 0.9891\n",
            "Epoch 27/50\n",
            "469/469 - 0s - loss: 0.0258 - accuracy: 0.9888\n",
            "Epoch 28/50\n",
            "469/469 - 0s - loss: 0.0234 - accuracy: 0.9901\n",
            "Epoch 29/50\n",
            "469/469 - 0s - loss: 0.0228 - accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "469/469 - 0s - loss: 0.0213 - accuracy: 0.9915\n",
            "Epoch 31/50\n",
            "469/469 - 0s - loss: 0.0213 - accuracy: 0.9908\n",
            "Epoch 32/50\n",
            "469/469 - 0s - loss: 0.0205 - accuracy: 0.9911\n",
            "Epoch 33/50\n",
            "469/469 - 0s - loss: 0.0189 - accuracy: 0.9921\n",
            "Epoch 34/50\n",
            "469/469 - 0s - loss: 0.0177 - accuracy: 0.9935\n",
            "Epoch 35/50\n",
            "469/469 - 0s - loss: 0.0179 - accuracy: 0.9927\n",
            "Epoch 36/50\n",
            "469/469 - 0s - loss: 0.0184 - accuracy: 0.9915\n",
            "Epoch 37/50\n",
            "469/469 - 0s - loss: 0.0180 - accuracy: 0.9922\n",
            "Epoch 38/50\n",
            "469/469 - 0s - loss: 0.0159 - accuracy: 0.9937\n",
            "Epoch 39/50\n",
            "469/469 - 0s - loss: 0.0202 - accuracy: 0.9915\n",
            "Epoch 40/50\n",
            "469/469 - 0s - loss: 0.0174 - accuracy: 0.9925\n",
            "Epoch 41/50\n",
            "469/469 - 0s - loss: 0.0173 - accuracy: 0.9925\n",
            "Epoch 42/50\n",
            "469/469 - 0s - loss: 0.0161 - accuracy: 0.9935\n",
            "Epoch 43/50\n",
            "469/469 - 0s - loss: 0.0164 - accuracy: 0.9927\n",
            "Epoch 44/50\n",
            "469/469 - 0s - loss: 0.0148 - accuracy: 0.9931\n",
            "Epoch 45/50\n",
            "469/469 - 0s - loss: 0.0160 - accuracy: 0.9935\n",
            "Epoch 46/50\n",
            "469/469 - 0s - loss: 0.0169 - accuracy: 0.9925\n",
            "Epoch 47/50\n",
            "469/469 - 0s - loss: 0.0165 - accuracy: 0.9929\n",
            "Epoch 48/50\n",
            "469/469 - 0s - loss: 0.0159 - accuracy: 0.9933\n",
            "Epoch 49/50\n",
            "469/469 - 0s - loss: 0.0152 - accuracy: 0.9937\n",
            "Epoch 50/50\n",
            "469/469 - 0s - loss: 0.0154 - accuracy: 0.9926\n",
            "confusion matrix: on test data set\n",
            "[[2238   26]\n",
            " [   4 2732]]\n",
            "errorRate 0.006\n",
            "N=200 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 3 out of 4 replications========\n",
            "shuffling 20000 entries\n",
            "[6467, 61, 8616, 19800, 5237, 1542, 18170, 15155, 10885, 11421]\n",
            "made 200 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 20000 good runs 111 bad runs 89\n",
            "2021-05-22 03:55:11\n",
            "Epoch 1/50\n",
            "469/469 - 1s - loss: 0.6339 - accuracy: 0.6773\n",
            "Epoch 2/50\n",
            "469/469 - 0s - loss: 0.3773 - accuracy: 0.8264\n",
            "Epoch 3/50\n",
            "469/469 - 0s - loss: 0.1646 - accuracy: 0.9374\n",
            "Epoch 4/50\n",
            "469/469 - 0s - loss: 0.1102 - accuracy: 0.9563\n",
            "Epoch 5/50\n",
            "469/469 - 0s - loss: 0.0951 - accuracy: 0.9609\n",
            "Epoch 6/50\n",
            "469/469 - 0s - loss: 0.0875 - accuracy: 0.9617\n",
            "Epoch 7/50\n",
            "469/469 - 0s - loss: 0.0824 - accuracy: 0.9633\n",
            "Epoch 8/50\n",
            "469/469 - 0s - loss: 0.0776 - accuracy: 0.9644\n",
            "Epoch 9/50\n",
            "469/469 - 0s - loss: 0.0738 - accuracy: 0.9683\n",
            "Epoch 10/50\n",
            "469/469 - 0s - loss: 0.0697 - accuracy: 0.9692\n",
            "Epoch 11/50\n",
            "469/469 - 0s - loss: 0.0673 - accuracy: 0.9699\n",
            "Epoch 12/50\n",
            "469/469 - 0s - loss: 0.0644 - accuracy: 0.9710\n",
            "Epoch 13/50\n",
            "469/469 - 0s - loss: 0.0597 - accuracy: 0.9725\n",
            "Epoch 14/50\n",
            "469/469 - 0s - loss: 0.0592 - accuracy: 0.9727\n",
            "Epoch 15/50\n",
            "469/469 - 0s - loss: 0.0559 - accuracy: 0.9747\n",
            "Epoch 16/50\n",
            "469/469 - 0s - loss: 0.0538 - accuracy: 0.9751\n",
            "Epoch 17/50\n",
            "469/469 - 0s - loss: 0.0520 - accuracy: 0.9764\n",
            "Epoch 18/50\n",
            "469/469 - 0s - loss: 0.0491 - accuracy: 0.9763\n",
            "Epoch 19/50\n",
            "469/469 - 0s - loss: 0.0466 - accuracy: 0.9789\n",
            "Epoch 20/50\n",
            "469/469 - 0s - loss: 0.0442 - accuracy: 0.9795\n",
            "Epoch 21/50\n",
            "469/469 - 0s - loss: 0.0444 - accuracy: 0.9788\n",
            "Epoch 22/50\n",
            "469/469 - 0s - loss: 0.0408 - accuracy: 0.9815\n",
            "Epoch 23/50\n",
            "469/469 - 0s - loss: 0.0388 - accuracy: 0.9831\n",
            "Epoch 24/50\n",
            "469/469 - 0s - loss: 0.0390 - accuracy: 0.9829\n",
            "Epoch 25/50\n",
            "469/469 - 0s - loss: 0.0358 - accuracy: 0.9831\n",
            "Epoch 26/50\n",
            "469/469 - 0s - loss: 0.0355 - accuracy: 0.9835\n",
            "Epoch 27/50\n",
            "469/469 - 0s - loss: 0.0360 - accuracy: 0.9837\n",
            "Epoch 28/50\n",
            "469/469 - 0s - loss: 0.0325 - accuracy: 0.9862\n",
            "Epoch 29/50\n",
            "469/469 - 0s - loss: 0.0310 - accuracy: 0.9853\n",
            "Epoch 30/50\n",
            "469/469 - 0s - loss: 0.0302 - accuracy: 0.9867\n",
            "Epoch 31/50\n",
            "469/469 - 0s - loss: 0.0295 - accuracy: 0.9865\n",
            "Epoch 32/50\n",
            "469/469 - 0s - loss: 0.0281 - accuracy: 0.9875\n",
            "Epoch 33/50\n",
            "469/469 - 0s - loss: 0.0290 - accuracy: 0.9877\n",
            "Epoch 34/50\n",
            "469/469 - 0s - loss: 0.0256 - accuracy: 0.9891\n",
            "Epoch 35/50\n",
            "469/469 - 0s - loss: 0.0249 - accuracy: 0.9891\n",
            "Epoch 36/50\n",
            "469/469 - 0s - loss: 0.0250 - accuracy: 0.9885\n",
            "Epoch 37/50\n",
            "469/469 - 0s - loss: 0.0256 - accuracy: 0.9891\n",
            "Epoch 38/50\n",
            "469/469 - 0s - loss: 0.0236 - accuracy: 0.9902\n",
            "Epoch 39/50\n",
            "469/469 - 0s - loss: 0.0219 - accuracy: 0.9906\n",
            "Epoch 40/50\n",
            "469/469 - 0s - loss: 0.0201 - accuracy: 0.9917\n",
            "Epoch 41/50\n",
            "469/469 - 0s - loss: 0.0223 - accuracy: 0.9901\n",
            "Epoch 42/50\n",
            "469/469 - 0s - loss: 0.0193 - accuracy: 0.9915\n",
            "Epoch 43/50\n",
            "469/469 - 0s - loss: 0.0219 - accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "469/469 - 0s - loss: 0.0185 - accuracy: 0.9925\n",
            "Epoch 45/50\n",
            "469/469 - 0s - loss: 0.0190 - accuracy: 0.9920\n",
            "Epoch 46/50\n",
            "469/469 - 0s - loss: 0.0189 - accuracy: 0.9922\n",
            "Epoch 47/50\n",
            "469/469 - 0s - loss: 0.0178 - accuracy: 0.9928\n",
            "Epoch 48/50\n",
            "469/469 - 0s - loss: 0.0168 - accuracy: 0.9930\n",
            "Epoch 49/50\n",
            "469/469 - 0s - loss: 0.0184 - accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "469/469 - 0s - loss: 0.0172 - accuracy: 0.9931\n",
            "confusion matrix: on test data set\n",
            "[[2205   19]\n",
            " [  25 2751]]\n",
            "errorRate 0.009\n",
            "N=200 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 4 out of 4 replications========\n",
            "The average error rate of 4 replications is:\n",
            "0.00605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT9vl1h14RKd"
      },
      "source": [
        "# INSERT ML algorithm here (X_rn, y_rn) train vs test sets\n",
        "\n",
        "\n",
        "#Mc=metrics.confusion_matrix(y_rn[int(testfraction*totalN):], y_pred)\n",
        "\n",
        "#totalN=Mc[0][0] + Mc[0][1] + Mc[1][0] + Mc[1][1]\n",
        "#misclassifiedN = Mc[0][1] + Mc[1][0]\n",
        "\n",
        "#errorRate= misclassifiedN / totalN\n",
        "\n",
        "#print(\"confusion matrix: on test data set\")\n",
        "#print(Mc)\n",
        "\n",
        "#print(\"errorRate %5.3f\" % errorRate)\n",
        "# print (strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "# print(\"N=%d : experiment_type: %s  road_input_type: %s\" % (nruns,experiment_type, road_input_type))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}