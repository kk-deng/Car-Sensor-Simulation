{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Pitstop2.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKBjhq8-TlIu"
      },
      "source": [
        "# Functions for Car Suspension Simulation\n",
        "*cleaned from cartsim_data.py*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YV07HtF4RJf"
      },
      "source": [
        "#define _FILE_SPECS \"-rw-r--r-- 1 chris 8007 Mar 25 12:33 cartsim_data.py\"\n",
        "#define _MAGIC_NUMBER 1147484068\n",
        "import numpy as np\n",
        "import math, os,   sys,  time\n",
        "from time import gmtime, strftime\n",
        "# from logger import logger\n",
        "from datetime import date, datetime, timezone\n",
        "import statistics as st\n",
        "import random as rn\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import random as rnn\n",
        " \n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "\n",
        "#equations\n",
        "# M \\ddot P = - C( X - X_0)  - D \\dot X\n",
        "#  P = X  + Z(Y(t))\n",
        "#  Y(t)= vt\n",
        "\n",
        "#  v=60km/hour = 16.666 m / sec\n",
        "#\n",
        "#  M= 1000kg\n",
        "#  X_0 =  5cm\n",
        "#  C spring const so 1000kg @ 10 m/sec^2 gives 5 cm ie\n",
        "#    =   5 x 10e-06\n",
        "#  X roughly +- 10cm\n",
        "#  road 3 components period   1 sec, 2 sec, 4 sec (random amplitude)\n",
        "#  sin(Y/(16.666)),  cos(Y/(16.666)), sin(Y/(2*16.66)), cos(Y/(2*16.66))\n",
        "#  choose D0 to efold in 1 second ie. D/2M = 1.0 --> D=2000\n",
        "#  too small is 'bad'\n",
        "#  choose sampling rate @ 4 Hz\n",
        "#  magnitude road = +- 5 max * sin( Y / 16.66 m)\n",
        "\n",
        "#  10 minute samples = 600 x 4 points @ 4 Hz\n",
        "#\n",
        "\n",
        "def Zbase ( trigtype, period, K, Y):\n",
        "    \n",
        "    if trigtype=='sin':\n",
        "        return math.sin( K * period * Y)\n",
        "    if trigtype=='cos':\n",
        "        return math.cos( K * period * Y)\n",
        "    \n",
        "def Zbaseddot ( trigtype, period, K, Y, v):\n",
        "    \n",
        "#     d^2/dt^ (VT)=0\n",
        "    if trigtype=='sin':\n",
        "        return -math.cos( K * period * Y) * v * v * (K /period) * (K/period)\n",
        "    if trigtype=='cos':\n",
        "        return -math.sin( K * period * Y) * v * v * (K /period) * (K/period)\n",
        "    \n",
        "def Xdot(Xn, Xnm1, dT):\n",
        "    return (Xn - Xnm1)/dT\n",
        "\n",
        "def Xddot(Xn, Xnm1, Xnm2, dT):\n",
        "    return (Xn - 2 * Xnm1  + Xnm2)/(dT * dT)\n",
        "\n",
        "def getXnp1(LHS, M, D, C, Xn, Xnm1, dT):\n",
        "# solve for Xnp1\n",
        "#  LHS = M(Xnp1 - 2 Xn + Xnm1)/delT^2 + D(Xnp1 - Xnm1)/2delT + C Xn\n",
        "  \n",
        "    rval = (LHS * dT * dT - (M - D * dT/2) * Xnm1  + (2 *M - C * dT * dT) * Xn  )/(M + D * dT/2) \n",
        "    \n",
        "    lv = M* (rval - 2 * Xn + Xnm1)/(dT * dT) + D* (rval - Xnm1)/(2*dT) + C * Xn\n",
        "    \n",
        "#    print(\"check %f = %f\" % (LHS,lv))\n",
        "          \n",
        "    return  rval\n",
        "\n",
        "def getLHSval(Zddval, Ms, Vs, Cs, X0s):\n",
        "# Cs * X0 =spring force\n",
        "    return - Ms * Zddval + Cs * X0s\n",
        "\n",
        "def zRoad(coeffs, v, Y, period, maxfreq):\n",
        "    \n",
        "    zR =0\n",
        "   \n",
        "    if maxfreq >= 0.5:\n",
        "       zR = coeffs[0]* Zbaseddot('cos', period, 0.5, Y, v) + zR\n",
        "       zR = coeffs[1]* Zbaseddot('sin', period, 0.5, Y, v) + zR\n",
        "\n",
        "    if maxfreq >= 1.0:\n",
        "       zR = coeffs[2]* Zbaseddot('cos', period, 1.0, Y, v) + zR\n",
        "       zR = coeffs[3]* Zbaseddot('sin', period, 1.0, Y, v) + zR\n",
        "    \n",
        "    if maxfreq >=2.0:\n",
        "       zR = coeffs[4]* Zbaseddot('cos', period, 2.0, Y, v) + zR\n",
        "       zR = coeffs[5]* Zbaseddot('sin', period, 2.0, Y, v) + zR\n",
        "       \n",
        "    if maxfreq >=4.0:\n",
        "       zR = coeffs[6]* Zbaseddot('cos', period, 4.0, Y, v) + zR\n",
        "       zR = coeffs[7]* Zbaseddot('sin', period, 4.0, Y, v) + zR\n",
        "    \n",
        "    return zR\n",
        "\n",
        "def  getRandomCoeffs(N):\n",
        "    \n",
        "     ampChoice=[0.01, 0.02, 0.025, 0.03, 0.035]\n",
        "     coeffs=[]\n",
        "\n",
        "     for i in range(0,N):\n",
        "          rAmpl1=rn.choice(ampChoice) \n",
        "#          rAmpl1=rAmpl\n",
        "          coeffs.append(rAmpl1)\n",
        "          \n",
        "     return coeffs\n",
        " \n",
        " \n",
        "\n",
        "def  compute_sim(M, D0, V, C, X0, delT, period, maxfreq, coeffs, topsample):\n",
        "    \n",
        "    Y=0\n",
        "# start with spring at rest\n",
        "    Xnp1=X0\n",
        "    Xn=X0\n",
        "    Xnm1=X0\n",
        "\n",
        "\n",
        "    springPos=[]\n",
        "    timeVal=[]\n",
        "    roadSurf=[]\n",
        "    \n",
        "     \n",
        "    for i in range(0, topsample):\n",
        "    \n",
        "        t= i * delT\n",
        "        timeVal.append(t)\n",
        "#        print(\"                T=%8.2f\" % t)\n",
        "    \n",
        "        Y= V * t  \n",
        "    \n",
        "        Zddval= zRoad(coeffs, V, Y, period, maxfreq)\n",
        "    \n",
        "#        print(\"Zddval %f\" % Zddval)\n",
        "    \n",
        "# LHS= -M (ddot (Z(Y))) + CX0\n",
        "        LHS= getLHSval(Zddval, M, V, C, X0)\n",
        "        roadSurf.append(LHS)\n",
        "    \n",
        "        Xnp1 = getXnp1(LHS, M, D0, C, Xn, Xnm1, delT)\n",
        "        springPos.append(Xnp1)\n",
        "    \n",
        "#        print(\"Xnp1 %8.3f  Xn %8.3f Xnm1 %8.3f\" % (Xnp1, Xn, Xnm1))\n",
        "    \n",
        "        Xnm1=Xn\n",
        "        Xn=Xnp1\n",
        "        \n",
        "    return [roadSurf, timeVal, springPos, t]\n",
        "\n",
        "def add_sample(M, D0, V, C, X0, delT, period, maxfreq, botsample, topsample, lval,Ncoeffs, Rcoeffs, road_input_type):\n",
        " # compute discriminant\n",
        "    disc= D0*D0 - 4 * M * C   \n",
        "    \n",
        "    [roadSurf, timeVals, springPos, tmax]= compute_sim(M, D0, V, C, X0, delT, period, maxfreq, Rcoeffs, topsample)\n",
        "\n",
        "    yval=[]\n",
        "    Xdat=[]\n",
        "\n",
        "#    print(\"sample D0=%d label=%s\" % (D0,lval )) \n",
        "#    print(\"D=%12.2f disc  %12.2f   maxfreq= %f\" % (D0, disc,   maxfreq))\n",
        "#    if disc < 0:\n",
        "#        print(\"sqrt = %f\" % math.sqrt(-disc))\n",
        " \n",
        "# assume botsample is > 3\n",
        "\n",
        "    if road_input_type=='vibration':\n",
        "        tupleLen=8\n",
        "    elif road_input_type=='surface':\n",
        "        tupleLen=2\n",
        "    else:\n",
        "        print(\"unknown road_type %s\" % road_type)\n",
        "        tupleLen=2\n",
        " \n",
        "# in this case include roadSurf = LHS as variable\n",
        "    xnorm=10000 \n",
        "    for i in range(botsample,topsample):\n",
        "        if tupleLen==2:\n",
        "# road input\n",
        "           Xdat.append([roadSurf[i]/xnorm, springPos[i-2], springPos[i-1], springPos[i]])\n",
        "# in vehicle vibration\n",
        "        elif tupleLen==5:\n",
        "           Xdat.append([springPos[i-5], springPos[i-4], springPos[i-3], springPos[i-2], springPos[i-1], springPos[i]])\n",
        "#  in vehicle vibration (long)\n",
        "        elif tupleLen==8:\n",
        "           Xdat.append([springPos[-8], springPos[-7], springPos[-6], springPos[i-5], springPos[i-4], springPos[i-3], springPos[i-2], springPos[i-1], springPos[i]])\n",
        "        else:\n",
        "            print(\"Unsupported tupleLen %d\" % tupleLen)\n",
        "            return [[],[]]\n",
        "        \n",
        "        yval.append(lval)\n",
        " \n",
        "    return [Xdat, yval]\n",
        "\n",
        "# This main function generates data based on user's selection of parameters    \n",
        "def generate_data(number_runs, experiment_type, observation_type):\n",
        "\n",
        "  # mass    \n",
        "  M=2000 \n",
        "  #   5cm compression\n",
        "  X0= 0.05\n",
        "  # spring const    \n",
        "\n",
        "  C= 0.6  * 10e+04\n",
        "  delT=0.25\n",
        "  # interesting values 500, 5000, 15000, 25000\n",
        "  \n",
        "  # damping\n",
        "  Dvalues=[5000, 5500, 6000, 6500, 4500, 4000, 3500, 500, 600, 700, 800, 400, 300, 200]\n",
        "\n",
        "  LABELvalues=['good','good', 'good', 'good', 'good','good','good','bad','bad','bad','bad','bad','bad','bad']\n",
        "\n",
        "  dindexlist=[x for x in range(0,14)]\n",
        "\n",
        "  \n",
        "  # car moves at 16.66 m/s\n",
        "  V= 16.66 \n",
        "  period= 16.66 \n",
        "  maxfreq=4.0\n",
        "  \n",
        "  botsample=400 \n",
        "  topsample=500\n",
        "  Ncoeffs=8\n",
        "\n",
        "  X=[]\n",
        "  y=[]\n",
        "  ngood=0\n",
        "  nbad=0\n",
        "\n",
        "  nruns = number_runs or 500\n",
        "  experiment_type= experiment_type or 'random_roads'\n",
        "  # experiment_type='standard_road'\n",
        "\n",
        "  # initialize road\n",
        "  Rcoeffs=getRandomCoeffs(Ncoeffs) \n",
        "\n",
        "  ldindexlist=[x for x in range(0, 100* nruns)]\n",
        "\n",
        "  for i in range(0,nruns):\n",
        "      \n",
        "            dindex=rn.choice(dindexlist)\n",
        "\n",
        "            D0=Dvalues[dindex]\n",
        "            labval=LABELvalues[dindex]\n",
        "      \n",
        "  \n",
        "            if experiment_type=='random_roads':\n",
        "                Rcoeffs=getRandomCoeffs(Ncoeffs)\n",
        "                \n",
        "\n",
        "  \n",
        "  #  For  in vehicle vibration road_input_type='vibration'\n",
        "  #  For  road input set road_input_type='surface'\n",
        "            \n",
        "            road_input_type = observation_type or 'surface'\n",
        "            #  road_input_type='vibration'\n",
        "  \n",
        "            [Xdat, yval]= add_sample(M, D0, V, C, X0, delT, period, maxfreq, botsample, topsample, labval,Ncoeffs, Rcoeffs, road_input_type)\n",
        "            \n",
        "  # [roadsurf, Xn-2, Xn-1, Xn]\n",
        "            if yval[0]=='good':\n",
        "                ngood+=1\n",
        "            if yval[0]=='bad':\n",
        "                nbad+=1\n",
        "  \n",
        "            for j in range(0, len(Xdat)):\n",
        "                  X.append(Xdat[j])\n",
        "                  y.append(yval[j])\n",
        "                  \n",
        "\n",
        "  print(\"shuffling %d entries\" % len(ldindexlist))\n",
        "  rn.shuffle(ldindexlist)\n",
        "  # sanity check\n",
        "  print(ldindexlist[0:10])\n",
        "\n",
        "  X_rn=[]\n",
        "  y_rn=[]\n",
        "\n",
        "  for i in range(0, len(X)):\n",
        "      X_rn.append(X[ldindexlist[i]])\n",
        "      y_rn.append(y[ldindexlist[i]])\n",
        "      \n",
        "      \n",
        "            \n",
        "  print(\"made %d samples with botsample %d topsample %d\" % (nruns,botsample, topsample))\n",
        "  print(\"maxfreq= %8.2f M= %8.2f V=%8.2f C=%8.2f\" % (maxfreq, M, V, C))\n",
        "\n",
        "  totalN=len(X)\n",
        "  print(\"Total samples %d good runs %d bad runs %d\" % (totalN, ngood, nbad))\n",
        "\n",
        "  #print(Xdat)\n",
        "\n",
        "  print (strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "\n",
        "  return X_rn, y_rn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lhBJiYa1V3h"
      },
      "source": [
        "# Analysis\n",
        "\n",
        "*Definitions of Accuracy and Error Rate*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAPMBWUBqhyd"
      },
      "source": [
        "The confusion matrix is a common metric to measure the performance of a classification algorithm. In this case, only \"good\" and \"bad\" are labelled (binary). So the confusion matrix can be shown as below:\n",
        "\n",
        "|               | Predicted(No) | Predicted(Yes)  |\n",
        "| ------------- |:---------------:| -----------------:|\n",
        "| **Actual(No)**   | True Negatives (TN) | False Positives (FP) |\n",
        "| **Actual(Yes)**  | False Negatives (FN) | True Positives (TP) |\n",
        "\n",
        "From the matrix, we could get the Accuracy by this formula:\n",
        "$$ Accuracy = \\frac {TP + TN}{TP + TN + FP + FN} $$\n",
        "\n",
        "And the Error rate would be $1-Accuracy$, same as\n",
        "$$ ErrorRate = \\frac {FP + FN}{TP + TN + FP + FN} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfJZFK8P6bsd"
      },
      "source": [
        "## Model Selection\n",
        "----\n",
        "\n",
        "Here is the summary table of all model candidates ranked by the Accuracy (via PyCaret)\n",
        "\n",
        "*Based on `500 N runs, random roads, and road input` *\n",
        "\n",
        "|Model|Accuracy|AUC|Recall|Prec.|F1|Kappa|MCC|TT (Sec)|\n",
        "|--- |--- |--- |--- |--- |--- |--- |--- |--- |\n",
        "|Extra Trees Classifier|0.9791|0.9983|0.9789|0.9806|0.9797|0.9582|0.9582|1.709|\n",
        "|Quadratic Discriminant Analysis|0.9783|0.9998|0.9579|1.0000|0.9785|0.9566|0.9576|0.036|\n",
        "|K Neighbors Classifier|0.9729|0.9955|0.9731|0.9742|0.9736|0.9457|0.9457|0.213|\n",
        "|Random Forest Classifier|0.9727|0.9969|0.9710|0.9759|0.9735|0.9454|0.9455|7.500|\n",
        "|Decision Tree Classifier|0.9477|0.9477|0.9472|0.9510|0.9491|0.8953|0.8953|0.244|\n",
        "|Light Gradient Boosting Machine|0.9339|0.9893|0.9651|0.9118|0.9376|0.8674|0.8691|0.360|\n",
        "|Gradient Boosting Classifier|0.8409|0.9444|0.9266|0.7973|0.8570|0.6799|0.6898|4.073|\n",
        "|Ada Boost Classifier|0.6967|0.7706|0.8287|0.6648|0.7377|0.3883|0.4018|1.082|\n",
        "|Naive Bayes|0.6476|0.6815|0.7716|0.6284|0.6926|0.2898|0.2983|0.032|\n",
        "|Linear Discriminant Analysis|0.5494|0.5109|0.9391|0.5356|0.6820|0.0768|0.1267|0.049|\n",
        "|Ridge Classifier|0.5278|0.0000|0.9967|0.5217|0.6849|0.0279|0.0915|0.031|\n",
        "|Logistic Regression|0.5148|0.5109|1.0000|0.5148|0.6797|0.0003|0.0039|0.379|\n",
        "|SVM - Linear Kernel|0.5147|0.0000|1.0000|0.5147|0.6796|0.0000|0.0000|0.062|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1XQJHld6iQW"
      },
      "source": [
        "Tree models and KNN have very good accuracy compared to other models. However, most of tree classifiers need more time to compute (takes seconds). Therefore, I chose the common **KNN model** as the estimator in this case, which has a pretty good Accuracy and AUC as well as short training time (0.213s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khXusr_hwnU0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSylfLynFt8g"
      },
      "source": [
        "## Define Function for Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2U5I0OopZ-q"
      },
      "source": [
        "# Create a function to generate model result\n",
        "def ml_result_report(y_test, y_pred):\n",
        "  # Create Confusion Matrix with testing and prediction data\n",
        "  Mc = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  totalN = Mc[0][0] + Mc[0][1] + Mc[1][0] + Mc[1][1]\n",
        "  misclassifiedN = Mc[0][1] + Mc[1][0]\n",
        "\n",
        "  errorRate = misclassifiedN / totalN\n",
        "\n",
        "  print(\"confusion matrix: on test data set\")\n",
        "  print(Mc)\n",
        "\n",
        "  print(\"errorRate %5.3f\" % errorRate)\n",
        "  # print (strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "  print(\"N=%d : experiment_type: %s  road_input_type: %s\" % (number_runs, experiment_type, observation_type))\n",
        "\n",
        "  return errorRate"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY3edCGrF45i"
      },
      "source": [
        "## Define a Model Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EFUs3zj152o"
      },
      "source": [
        "# Create a pipeline to train model and then predict\n",
        "def model_pipeline(X_rn, y_rn, model):\n",
        "  # Split samples\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_rn, y_rn, test_size=testfraction, random_state=42)\n",
        "\n",
        "  # Standardization of sample\n",
        "  X_scaler = StandardScaler().fit(X_train)\n",
        "  X_train_scaled = X_scaler.transform(X_train)\n",
        "  X_test_scaled = X_scaler.transform(X_test)\n",
        "\n",
        "  # Train model\n",
        "  model.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # Print out score\n",
        "  train_score = model.score(X_train_scaled, y_train)\n",
        "  model_score = model.score(X_test_scaled, y_test)\n",
        "  print(\"Train score: %5.4f\" % train_score)\n",
        "  print(\"Model score: %5.4f\" % model_score)\n",
        "\n",
        "  # Get predict data\n",
        "  y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "  return y_test, y_pred"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGo0Rec1F8TI"
      },
      "source": [
        "## Define Main Function to Run 4 Replications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPZWTID3E88n"
      },
      "source": [
        "# A main function to generate avg error rate\n",
        "def compute_avg_err_rate(model):\n",
        "  \n",
        "  list_err_rate = []\n",
        "\n",
        "  # Main function to generate required data\n",
        "  for i in range(4):\n",
        "    X_rn, y_rn = generate_data(number_runs, experiment_type, observation_type)\n",
        "\n",
        "    y_test, y_pred = model_pipeline(X_rn, y_rn, knn)\n",
        "    err_rate = ml_result_report(y_test, y_pred)\n",
        "\n",
        "    list_err_rate.append(err_rate)\n",
        "    print(\"========== %s out of 4 replications========\" % (i+1))\n",
        "\n",
        "  print(\"The average error rate of 4 replications is:\")\n",
        "  print(sum(list_err_rate)/len(list_err_rate))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glroNK1BFhJ1"
      },
      "source": [
        "# Generate Data and Return result with 3 Models\n",
        "\n",
        "3 different models were built and ran for 4 times for each to calculate the error rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX2g3LGZJ2X6"
      },
      "source": [
        "## Parameter Settings for Each Case\n",
        "\n",
        "N runs, Experiment type, Observation type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPNp5dJw9V16"
      },
      "source": [
        "#====================================================\n",
        "# Here is the list of parameter variables\n",
        "# Change the following variable values for each case\n",
        "#----------------------------------------------------\n",
        "number_runs = 500\n",
        "# experiment_type = \"standard_road\"\n",
        "experiment_type = \"random_roads\"\n",
        "\n",
        "# observation_type = \"surface\"\n",
        "observation_type = \"vibration\"\n",
        "testfraction = 0.3\n",
        "#===================================================="
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtTd5_ykKDoX"
      },
      "source": [
        "## KNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7k5MyPu74RKX",
        "outputId": "95d6c22f-9c13-413f-cb53-a1e9f67fa867"
      },
      "source": [
        "# KNN\n",
        "# A n_neighbors vs accuracy plotting was done separately\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "compute_avg_err_rate(knn)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shuffling 50000 entries\n",
            "[36867, 19471, 28194, 10806, 7384, 45232, 8538, 18767, 45858, 33489]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 276 bad runs 224\n",
            "2021-05-22 03:34:16\n",
            "Train score: 0.9919\n",
            "Model score: 0.9810\n",
            "confusion matrix: on test data set\n",
            "[[6557  172]\n",
            " [ 113 8158]]\n",
            "errorRate 0.019\n",
            "N=500 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 1 out of 4 replications========\n",
            "shuffling 50000 entries\n",
            "[26961, 14535, 40783, 11357, 960, 23015, 23381, 28512, 4891, 11422]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 245 bad runs 255\n",
            "2021-05-22 03:34:20\n",
            "Train score: 0.9917\n",
            "Model score: 0.9819\n",
            "confusion matrix: on test data set\n",
            "[[7595  135]\n",
            " [ 136 7134]]\n",
            "errorRate 0.018\n",
            "N=500 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 2 out of 4 replications========\n",
            "shuffling 50000 entries\n",
            "[47470, 9887, 39341, 23228, 20070, 33651, 45633, 12605, 20394, 9319]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 235 bad runs 265\n",
            "2021-05-22 03:34:24\n",
            "Train score: 0.9915\n",
            "Model score: 0.9809\n",
            "confusion matrix: on test data set\n",
            "[[7830  126]\n",
            " [ 160 6884]]\n",
            "errorRate 0.019\n",
            "N=500 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 3 out of 4 replications========\n",
            "shuffling 50000 entries\n",
            "[44107, 10659, 14686, 13563, 20574, 15656, 34654, 47319, 31487, 11567]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 250 bad runs 250\n",
            "2021-05-22 03:34:28\n",
            "Train score: 0.9915\n",
            "Model score: 0.9797\n",
            "confusion matrix: on test data set\n",
            "[[7411  159]\n",
            " [ 145 7285]]\n",
            "errorRate 0.020\n",
            "N=500 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 4 out of 4 replications========\n",
            "The average error rate of 4 replications is:\n",
            "0.0191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLf83g6ZKHL-"
      },
      "source": [
        "## Naive Bayes Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "y6Q1J0RQ4RKb",
        "outputId": "a5ef35ba-08ef-43d4-cceb-8aface080a49"
      },
      "source": [
        "# NB\n",
        "nb = MultinomialNB()\n",
        "compute_avg_err_rate(nb)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shuffling 100000 entries\n",
            "[19517, 44713, 30003, 87982, 34762, 12576, 42558, 70632, 92770, 90467]\n",
            "made 1000 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 100000 good runs 501 bad runs 499\n",
            "2021-05-22 03:43:27\n",
            "Train score: 0.9937\n",
            "Model score: 0.9853\n",
            "confusion matrix: on test data set\n",
            "[[14715   195]\n",
            " [  247 14843]]\n",
            "errorRate 0.015\n",
            "N=1000 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 1 out of 4 replications========\n",
            "shuffling 100000 entries\n",
            "[32176, 47261, 78775, 93805, 34278, 97122, 31867, 12869, 74862, 42504]\n",
            "made 1000 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 100000 good runs 466 bad runs 534\n",
            "2021-05-22 03:43:35\n",
            "Train score: 0.9939\n",
            "Model score: 0.9858\n",
            "confusion matrix: on test data set\n",
            "[[15895   186]\n",
            " [  241 13678]]\n",
            "errorRate 0.014\n",
            "N=1000 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 2 out of 4 replications========\n",
            "shuffling 100000 entries\n",
            "[32047, 78310, 92075, 65259, 58778, 69893, 52113, 62482, 3243, 21077]\n",
            "made 1000 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 100000 good runs 501 bad runs 499\n",
            "2021-05-22 03:43:44\n",
            "Train score: 0.9945\n",
            "Model score: 0.9863\n",
            "confusion matrix: on test data set\n",
            "[[14786   202]\n",
            " [  209 14803]]\n",
            "errorRate 0.014\n",
            "N=1000 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 3 out of 4 replications========\n",
            "shuffling 100000 entries\n",
            "[84647, 20037, 48912, 80936, 8581, 13911, 12483, 4749, 74449, 75944]\n",
            "made 1000 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 100000 good runs 500 bad runs 500\n",
            "2021-05-22 03:43:52\n",
            "Train score: 0.9927\n",
            "Model score: 0.9846\n",
            "confusion matrix: on test data set\n",
            "[[14828   183]\n",
            " [  278 14711]]\n",
            "errorRate 0.015\n",
            "N=1000 : experiment_type: random_roads  road_input_type: surface\n",
            "========== 4 out of 4 replications========\n",
            "The average error rate of 4 replications is:\n",
            "0.014508333333333335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blXHIrju4ctv"
      },
      "source": [
        "## Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJVz2eBXm0mJ"
      },
      "source": [
        "def nn_compute_avg_err_rate():\n",
        "\n",
        "  list_err_rate = []\n",
        "  # Main function to generate required data\n",
        "  for i in range(4):\n",
        "    X_rn, y_rn = generate_data(number_runs, experiment_type, observation_type)\n",
        "    \n",
        "    # Split samples\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_rn, y_rn, random_state=42)\n",
        "\n",
        "    # Standardization\n",
        "    X_scaler = StandardScaler().fit(X_train)\n",
        "    X_train_scaled = X_scaler.transform(X_train)\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "\n",
        "    # Transform y values\n",
        "    label_model = LabelEncoder()\n",
        "    label_model.fit(y_train)\n",
        "\n",
        "    y_train_encoded = label_model.transform(y_train)\n",
        "    y_test_encoded = label_model.transform(y_test)\n",
        "\n",
        "    # Convert to categorical data\n",
        "    y_train_categorical = to_categorical(y_train_encoded)\n",
        "    y_test_categorical = to_categorical(y_test_encoded)\n",
        "\n",
        "    # Building NN model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=9, activation=\"relu\", input_dim=9))\n",
        "    model.add(Dense(units=20, activation=\"relu\"))\n",
        "    model.add(Dense(units=5, activation=\"relu\"))\n",
        "    model.add(Dense(units=2, activation=\"softmax\"))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "    # Fitting model\n",
        "    model.fit(X_train_scaled, y_train_categorical, epochs=50, shuffle=True, verbose=2)\n",
        "\n",
        "    # Predit values\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_pred\n",
        "\n",
        "    # confusion_matrix(y_test_categorical.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "    err_rate = ml_result_report(y_test_categorical.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "\n",
        "    list_err_rate.append(err_rate)\n",
        "    print(\"========== %s out of 4 replications========\" % (i+1))\n",
        "\n",
        "  print(\"The average error rate of 4 replications is:\")\n",
        "  print(sum(list_err_rate)/len(list_err_rate))\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fc_b3HwEM_8z",
        "outputId": "848764e7-f3b2-4264-f2e6-8a2361ee54b9"
      },
      "source": [
        "# Run MLP function\n",
        "nn_compute_avg_err_rate()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shuffling 50000 entries\n",
            "[24470, 5893, 26005, 19684, 21444, 22444, 4785, 6573, 12679, 38143]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 269 bad runs 231\n",
            "2021-05-22 04:24:01\n",
            "Epoch 1/50\n",
            "1172/1172 - 2s - loss: 0.3837 - accuracy: 0.8120\n",
            "Epoch 2/50\n",
            "1172/1172 - 1s - loss: 0.3049 - accuracy: 0.8523\n",
            "Epoch 3/50\n",
            "1172/1172 - 1s - loss: 0.2686 - accuracy: 0.8649\n",
            "Epoch 4/50\n",
            "1172/1172 - 1s - loss: 0.2490 - accuracy: 0.8711\n",
            "Epoch 5/50\n",
            "1172/1172 - 1s - loss: 0.2338 - accuracy: 0.8786\n",
            "Epoch 6/50\n",
            "1172/1172 - 1s - loss: 0.2226 - accuracy: 0.8856\n",
            "Epoch 7/50\n",
            "1172/1172 - 1s - loss: 0.2124 - accuracy: 0.8908\n",
            "Epoch 8/50\n",
            "1172/1172 - 1s - loss: 0.2040 - accuracy: 0.8965\n",
            "Epoch 9/50\n",
            "1172/1172 - 1s - loss: 0.1970 - accuracy: 0.8991\n",
            "Epoch 10/50\n",
            "1172/1172 - 1s - loss: 0.1915 - accuracy: 0.9017\n",
            "Epoch 11/50\n",
            "1172/1172 - 1s - loss: 0.1877 - accuracy: 0.9033\n",
            "Epoch 12/50\n",
            "1172/1172 - 1s - loss: 0.1833 - accuracy: 0.9069\n",
            "Epoch 13/50\n",
            "1172/1172 - 1s - loss: 0.1801 - accuracy: 0.9099\n",
            "Epoch 14/50\n",
            "1172/1172 - 1s - loss: 0.1765 - accuracy: 0.9129\n",
            "Epoch 15/50\n",
            "1172/1172 - 1s - loss: 0.1735 - accuracy: 0.9146\n",
            "Epoch 16/50\n",
            "1172/1172 - 1s - loss: 0.1713 - accuracy: 0.9162\n",
            "Epoch 17/50\n",
            "1172/1172 - 1s - loss: 0.1692 - accuracy: 0.9157\n",
            "Epoch 18/50\n",
            "1172/1172 - 1s - loss: 0.1664 - accuracy: 0.9176\n",
            "Epoch 19/50\n",
            "1172/1172 - 1s - loss: 0.1634 - accuracy: 0.9191\n",
            "Epoch 20/50\n",
            "1172/1172 - 1s - loss: 0.1594 - accuracy: 0.9211\n",
            "Epoch 21/50\n",
            "1172/1172 - 1s - loss: 0.1554 - accuracy: 0.9225\n",
            "Epoch 22/50\n",
            "1172/1172 - 1s - loss: 0.1514 - accuracy: 0.9238\n",
            "Epoch 23/50\n",
            "1172/1172 - 1s - loss: 0.1477 - accuracy: 0.9240\n",
            "Epoch 24/50\n",
            "1172/1172 - 1s - loss: 0.1431 - accuracy: 0.9265\n",
            "Epoch 25/50\n",
            "1172/1172 - 1s - loss: 0.1395 - accuracy: 0.9284\n",
            "Epoch 26/50\n",
            "1172/1172 - 1s - loss: 0.1353 - accuracy: 0.9300\n",
            "Epoch 27/50\n",
            "1172/1172 - 1s - loss: 0.1316 - accuracy: 0.9328\n",
            "Epoch 28/50\n",
            "1172/1172 - 1s - loss: 0.1289 - accuracy: 0.9342\n",
            "Epoch 29/50\n",
            "1172/1172 - 1s - loss: 0.1254 - accuracy: 0.9374\n",
            "Epoch 30/50\n",
            "1172/1172 - 1s - loss: 0.1223 - accuracy: 0.9396\n",
            "Epoch 31/50\n",
            "1172/1172 - 1s - loss: 0.1181 - accuracy: 0.9430\n",
            "Epoch 32/50\n",
            "1172/1172 - 1s - loss: 0.1164 - accuracy: 0.9427\n",
            "Epoch 33/50\n",
            "1172/1172 - 1s - loss: 0.1137 - accuracy: 0.9450\n",
            "Epoch 34/50\n",
            "1172/1172 - 1s - loss: 0.1123 - accuracy: 0.9448\n",
            "Epoch 35/50\n",
            "1172/1172 - 1s - loss: 0.1104 - accuracy: 0.9455\n",
            "Epoch 36/50\n",
            "1172/1172 - 1s - loss: 0.1085 - accuracy: 0.9464\n",
            "Epoch 37/50\n",
            "1172/1172 - 1s - loss: 0.1050 - accuracy: 0.9494\n",
            "Epoch 38/50\n",
            "1172/1172 - 1s - loss: 0.1041 - accuracy: 0.9508\n",
            "Epoch 39/50\n",
            "1172/1172 - 1s - loss: 0.1016 - accuracy: 0.9513\n",
            "Epoch 40/50\n",
            "1172/1172 - 1s - loss: 0.1022 - accuracy: 0.9511\n",
            "Epoch 41/50\n",
            "1172/1172 - 1s - loss: 0.0973 - accuracy: 0.9543\n",
            "Epoch 42/50\n",
            "1172/1172 - 1s - loss: 0.0964 - accuracy: 0.9549\n",
            "Epoch 43/50\n",
            "1172/1172 - 1s - loss: 0.0951 - accuracy: 0.9557\n",
            "Epoch 44/50\n",
            "1172/1172 - 1s - loss: 0.0946 - accuracy: 0.9565\n",
            "Epoch 45/50\n",
            "1172/1172 - 1s - loss: 0.0943 - accuracy: 0.9554\n",
            "Epoch 46/50\n",
            "1172/1172 - 1s - loss: 0.0932 - accuracy: 0.9572\n",
            "Epoch 47/50\n",
            "1172/1172 - 1s - loss: 0.0893 - accuracy: 0.9588\n",
            "Epoch 48/50\n",
            "1172/1172 - 1s - loss: 0.0874 - accuracy: 0.9609\n",
            "Epoch 49/50\n",
            "1172/1172 - 1s - loss: 0.0860 - accuracy: 0.9621\n",
            "Epoch 50/50\n",
            "1172/1172 - 1s - loss: 0.0832 - accuracy: 0.9620\n",
            "confusion matrix: on test data set\n",
            "[[5710  144]\n",
            " [ 231 6415]]\n",
            "errorRate 0.030\n",
            "N=500 : experiment_type: random_roads  road_input_type: vibration\n",
            "========== 1 out of 4 replications========\n",
            "shuffling 50000 entries\n",
            "[18187, 5751, 38371, 32975, 10383, 45950, 13163, 31158, 14589, 40309]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 255 bad runs 245\n",
            "2021-05-22 04:25:00\n",
            "Epoch 1/50\n",
            "1172/1172 - 2s - loss: 0.3860 - accuracy: 0.8113\n",
            "Epoch 2/50\n",
            "1172/1172 - 1s - loss: 0.2964 - accuracy: 0.8455\n",
            "Epoch 3/50\n",
            "1172/1172 - 1s - loss: 0.2612 - accuracy: 0.8600\n",
            "Epoch 4/50\n",
            "1172/1172 - 1s - loss: 0.2401 - accuracy: 0.8728\n",
            "Epoch 5/50\n",
            "1172/1172 - 1s - loss: 0.2278 - accuracy: 0.8808\n",
            "Epoch 6/50\n",
            "1172/1172 - 1s - loss: 0.2195 - accuracy: 0.8805\n",
            "Epoch 7/50\n",
            "1172/1172 - 1s - loss: 0.2118 - accuracy: 0.8858\n",
            "Epoch 8/50\n",
            "1172/1172 - 1s - loss: 0.2067 - accuracy: 0.8888\n",
            "Epoch 9/50\n",
            "1172/1172 - 1s - loss: 0.2018 - accuracy: 0.8910\n",
            "Epoch 10/50\n",
            "1172/1172 - 1s - loss: 0.1975 - accuracy: 0.8928\n",
            "Epoch 11/50\n",
            "1172/1172 - 1s - loss: 0.1932 - accuracy: 0.8978\n",
            "Epoch 12/50\n",
            "1172/1172 - 1s - loss: 0.1873 - accuracy: 0.9036\n",
            "Epoch 13/50\n",
            "1172/1172 - 1s - loss: 0.1825 - accuracy: 0.9072\n",
            "Epoch 14/50\n",
            "1172/1172 - 1s - loss: 0.1769 - accuracy: 0.9108\n",
            "Epoch 15/50\n",
            "1172/1172 - 1s - loss: 0.1714 - accuracy: 0.9159\n",
            "Epoch 16/50\n",
            "1172/1172 - 1s - loss: 0.1666 - accuracy: 0.9182\n",
            "Epoch 17/50\n",
            "1172/1172 - 1s - loss: 0.1614 - accuracy: 0.9227\n",
            "Epoch 18/50\n",
            "1172/1172 - 1s - loss: 0.1558 - accuracy: 0.9253\n",
            "Epoch 19/50\n",
            "1172/1172 - 1s - loss: 0.1512 - accuracy: 0.9283\n",
            "Epoch 20/50\n",
            "1172/1172 - 1s - loss: 0.1459 - accuracy: 0.9317\n",
            "Epoch 21/50\n",
            "1172/1172 - 1s - loss: 0.1428 - accuracy: 0.9336\n",
            "Epoch 22/50\n",
            "1172/1172 - 1s - loss: 0.1399 - accuracy: 0.9355\n",
            "Epoch 23/50\n",
            "1172/1172 - 1s - loss: 0.1357 - accuracy: 0.9379\n",
            "Epoch 24/50\n",
            "1172/1172 - 1s - loss: 0.1337 - accuracy: 0.9387\n",
            "Epoch 25/50\n",
            "1172/1172 - 1s - loss: 0.1308 - accuracy: 0.9393\n",
            "Epoch 26/50\n",
            "1172/1172 - 1s - loss: 0.1277 - accuracy: 0.9410\n",
            "Epoch 27/50\n",
            "1172/1172 - 1s - loss: 0.1271 - accuracy: 0.9423\n",
            "Epoch 28/50\n",
            "1172/1172 - 1s - loss: 0.1238 - accuracy: 0.9435\n",
            "Epoch 29/50\n",
            "1172/1172 - 1s - loss: 0.1230 - accuracy: 0.9444\n",
            "Epoch 30/50\n",
            "1172/1172 - 1s - loss: 0.1207 - accuracy: 0.9459\n",
            "Epoch 31/50\n",
            "1172/1172 - 1s - loss: 0.1187 - accuracy: 0.9459\n",
            "Epoch 32/50\n",
            "1172/1172 - 1s - loss: 0.1186 - accuracy: 0.9467\n",
            "Epoch 33/50\n",
            "1172/1172 - 1s - loss: 0.1155 - accuracy: 0.9481\n",
            "Epoch 34/50\n",
            "1172/1172 - 1s - loss: 0.1163 - accuracy: 0.9469\n",
            "Epoch 35/50\n",
            "1172/1172 - 1s - loss: 0.1132 - accuracy: 0.9487\n",
            "Epoch 36/50\n",
            "1172/1172 - 1s - loss: 0.1120 - accuracy: 0.9489\n",
            "Epoch 37/50\n",
            "1172/1172 - 1s - loss: 0.1108 - accuracy: 0.9512\n",
            "Epoch 38/50\n",
            "1172/1172 - 1s - loss: 0.1106 - accuracy: 0.9504\n",
            "Epoch 39/50\n",
            "1172/1172 - 1s - loss: 0.1078 - accuracy: 0.9517\n",
            "Epoch 40/50\n",
            "1172/1172 - 1s - loss: 0.1058 - accuracy: 0.9536\n",
            "Epoch 41/50\n",
            "1172/1172 - 1s - loss: 0.1055 - accuracy: 0.9540\n",
            "Epoch 42/50\n",
            "1172/1172 - 1s - loss: 0.1047 - accuracy: 0.9541\n",
            "Epoch 43/50\n",
            "1172/1172 - 1s - loss: 0.1022 - accuracy: 0.9549\n",
            "Epoch 44/50\n",
            "1172/1172 - 1s - loss: 0.1022 - accuracy: 0.9561\n",
            "Epoch 45/50\n",
            "1172/1172 - 1s - loss: 0.1008 - accuracy: 0.9553\n",
            "Epoch 46/50\n",
            "1172/1172 - 1s - loss: 0.0994 - accuracy: 0.9559\n",
            "Epoch 47/50\n",
            "1172/1172 - 1s - loss: 0.1095 - accuracy: 0.9513\n",
            "Epoch 48/50\n",
            "1172/1172 - 1s - loss: 0.1011 - accuracy: 0.9547\n",
            "Epoch 49/50\n",
            "1172/1172 - 1s - loss: 0.0974 - accuracy: 0.9575\n",
            "Epoch 50/50\n",
            "1172/1172 - 1s - loss: 0.0939 - accuracy: 0.9581\n",
            "confusion matrix: on test data set\n",
            "[[6019  128]\n",
            " [ 447 5906]]\n",
            "errorRate 0.046\n",
            "N=500 : experiment_type: random_roads  road_input_type: vibration\n",
            "========== 2 out of 4 replications========\n",
            "shuffling 50000 entries\n",
            "[35517, 37903, 14258, 11337, 6816, 10559, 45441, 22051, 35836, 32625]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 238 bad runs 262\n",
            "2021-05-22 04:25:59\n",
            "Epoch 1/50\n",
            "1172/1172 - 2s - loss: 0.3455 - accuracy: 0.8418\n",
            "Epoch 2/50\n",
            "1172/1172 - 1s - loss: 0.2753 - accuracy: 0.8724\n",
            "Epoch 3/50\n",
            "1172/1172 - 1s - loss: 0.2453 - accuracy: 0.8793\n",
            "Epoch 4/50\n",
            "1172/1172 - 1s - loss: 0.2299 - accuracy: 0.8840\n",
            "Epoch 5/50\n",
            "1172/1172 - 1s - loss: 0.2199 - accuracy: 0.8913\n",
            "Epoch 6/50\n",
            "1172/1172 - 1s - loss: 0.2114 - accuracy: 0.8967\n",
            "Epoch 7/50\n",
            "1172/1172 - 1s - loss: 0.2058 - accuracy: 0.8977\n",
            "Epoch 8/50\n",
            "1172/1172 - 1s - loss: 0.1991 - accuracy: 0.9025\n",
            "Epoch 9/50\n",
            "1172/1172 - 1s - loss: 0.1920 - accuracy: 0.9033\n",
            "Epoch 10/50\n",
            "1172/1172 - 1s - loss: 0.1866 - accuracy: 0.9045\n",
            "Epoch 11/50\n",
            "1172/1172 - 1s - loss: 0.1809 - accuracy: 0.9067\n",
            "Epoch 12/50\n",
            "1172/1172 - 1s - loss: 0.1770 - accuracy: 0.9089\n",
            "Epoch 13/50\n",
            "1172/1172 - 1s - loss: 0.1711 - accuracy: 0.9116\n",
            "Epoch 14/50\n",
            "1172/1172 - 1s - loss: 0.1663 - accuracy: 0.9164\n",
            "Epoch 15/50\n",
            "1172/1172 - 1s - loss: 0.1624 - accuracy: 0.9199\n",
            "Epoch 16/50\n",
            "1172/1172 - 1s - loss: 0.1588 - accuracy: 0.9222\n",
            "Epoch 17/50\n",
            "1172/1172 - 1s - loss: 0.1559 - accuracy: 0.9232\n",
            "Epoch 18/50\n",
            "1172/1172 - 1s - loss: 0.1534 - accuracy: 0.9243\n",
            "Epoch 19/50\n",
            "1172/1172 - 1s - loss: 0.1506 - accuracy: 0.9267\n",
            "Epoch 20/50\n",
            "1172/1172 - 1s - loss: 0.1484 - accuracy: 0.9270\n",
            "Epoch 21/50\n",
            "1172/1172 - 1s - loss: 0.1468 - accuracy: 0.9283\n",
            "Epoch 22/50\n",
            "1172/1172 - 1s - loss: 0.1438 - accuracy: 0.9301\n",
            "Epoch 23/50\n",
            "1172/1172 - 1s - loss: 0.1421 - accuracy: 0.9306\n",
            "Epoch 24/50\n",
            "1172/1172 - 1s - loss: 0.1392 - accuracy: 0.9325\n",
            "Epoch 25/50\n",
            "1172/1172 - 1s - loss: 0.1365 - accuracy: 0.9326\n",
            "Epoch 26/50\n",
            "1172/1172 - 1s - loss: 0.1346 - accuracy: 0.9350\n",
            "Epoch 27/50\n",
            "1172/1172 - 1s - loss: 0.1327 - accuracy: 0.9365\n",
            "Epoch 28/50\n",
            "1172/1172 - 1s - loss: 0.1298 - accuracy: 0.9376\n",
            "Epoch 29/50\n",
            "1172/1172 - 1s - loss: 0.1283 - accuracy: 0.9377\n",
            "Epoch 30/50\n",
            "1172/1172 - 1s - loss: 0.1262 - accuracy: 0.9385\n",
            "Epoch 31/50\n",
            "1172/1172 - 1s - loss: 0.1244 - accuracy: 0.9402\n",
            "Epoch 32/50\n",
            "1172/1172 - 1s - loss: 0.1227 - accuracy: 0.9406\n",
            "Epoch 33/50\n",
            "1172/1172 - 1s - loss: 0.1213 - accuracy: 0.9409\n",
            "Epoch 34/50\n",
            "1172/1172 - 1s - loss: 0.1185 - accuracy: 0.9440\n",
            "Epoch 35/50\n",
            "1172/1172 - 1s - loss: 0.1160 - accuracy: 0.9438\n",
            "Epoch 36/50\n",
            "1172/1172 - 1s - loss: 0.1139 - accuracy: 0.9446\n",
            "Epoch 37/50\n",
            "1172/1172 - 1s - loss: 0.1108 - accuracy: 0.9470\n",
            "Epoch 38/50\n",
            "1172/1172 - 1s - loss: 0.1080 - accuracy: 0.9501\n",
            "Epoch 39/50\n",
            "1172/1172 - 1s - loss: 0.1029 - accuracy: 0.9532\n",
            "Epoch 40/50\n",
            "1172/1172 - 1s - loss: 0.0998 - accuracy: 0.9553\n",
            "Epoch 41/50\n",
            "1172/1172 - 1s - loss: 0.0965 - accuracy: 0.9564\n",
            "Epoch 42/50\n",
            "1172/1172 - 1s - loss: 0.0937 - accuracy: 0.9576\n",
            "Epoch 43/50\n",
            "1172/1172 - 1s - loss: 0.0903 - accuracy: 0.9585\n",
            "Epoch 44/50\n",
            "1172/1172 - 1s - loss: 0.0877 - accuracy: 0.9588\n",
            "Epoch 45/50\n",
            "1172/1172 - 1s - loss: 0.0844 - accuracy: 0.9605\n",
            "Epoch 46/50\n",
            "1172/1172 - 1s - loss: 0.0829 - accuracy: 0.9611\n",
            "Epoch 47/50\n",
            "1172/1172 - 1s - loss: 0.0805 - accuracy: 0.9606\n",
            "Epoch 48/50\n",
            "1172/1172 - 1s - loss: 0.0784 - accuracy: 0.9629\n",
            "Epoch 49/50\n",
            "1172/1172 - 1s - loss: 0.0785 - accuracy: 0.9637\n",
            "Epoch 50/50\n",
            "1172/1172 - 1s - loss: 0.0751 - accuracy: 0.9635\n",
            "confusion matrix: on test data set\n",
            "[[6402  164]\n",
            " [ 272 5662]]\n",
            "errorRate 0.035\n",
            "N=500 : experiment_type: random_roads  road_input_type: vibration\n",
            "========== 3 out of 4 replications========\n",
            "shuffling 50000 entries\n",
            "[29117, 27359, 25986, 1623, 36066, 47781, 35969, 26477, 48671, 23167]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 252 bad runs 248\n",
            "2021-05-22 04:26:58\n",
            "Epoch 1/50\n",
            "1172/1172 - 2s - loss: 0.3077 - accuracy: 0.8770\n",
            "Epoch 2/50\n",
            "1172/1172 - 1s - loss: 0.2556 - accuracy: 0.8967\n",
            "Epoch 3/50\n",
            "1172/1172 - 1s - loss: 0.2382 - accuracy: 0.9000\n",
            "Epoch 4/50\n",
            "1172/1172 - 1s - loss: 0.2173 - accuracy: 0.9007\n",
            "Epoch 5/50\n",
            "1172/1172 - 1s - loss: 0.2025 - accuracy: 0.9044\n",
            "Epoch 6/50\n",
            "1172/1172 - 1s - loss: 0.1931 - accuracy: 0.9102\n",
            "Epoch 7/50\n",
            "1172/1172 - 1s - loss: 0.1868 - accuracy: 0.9123\n",
            "Epoch 8/50\n",
            "1172/1172 - 1s - loss: 0.1821 - accuracy: 0.9132\n",
            "Epoch 9/50\n",
            "1172/1172 - 1s - loss: 0.1780 - accuracy: 0.9154\n",
            "Epoch 10/50\n",
            "1172/1172 - 1s - loss: 0.1715 - accuracy: 0.9202\n",
            "Epoch 11/50\n",
            "1172/1172 - 1s - loss: 0.1660 - accuracy: 0.9226\n",
            "Epoch 12/50\n",
            "1172/1172 - 1s - loss: 0.1612 - accuracy: 0.9256\n",
            "Epoch 13/50\n",
            "1172/1172 - 1s - loss: 0.1571 - accuracy: 0.9278\n",
            "Epoch 14/50\n",
            "1172/1172 - 1s - loss: 0.1536 - accuracy: 0.9309\n",
            "Epoch 15/50\n",
            "1172/1172 - 1s - loss: 0.1511 - accuracy: 0.9312\n",
            "Epoch 16/50\n",
            "1172/1172 - 1s - loss: 0.1473 - accuracy: 0.9323\n",
            "Epoch 17/50\n",
            "1172/1172 - 1s - loss: 0.1448 - accuracy: 0.9337\n",
            "Epoch 18/50\n",
            "1172/1172 - 1s - loss: 0.1415 - accuracy: 0.9347\n",
            "Epoch 19/50\n",
            "1172/1172 - 1s - loss: 0.1378 - accuracy: 0.9371\n",
            "Epoch 20/50\n",
            "1172/1172 - 1s - loss: 0.1358 - accuracy: 0.9370\n",
            "Epoch 21/50\n",
            "1172/1172 - 1s - loss: 0.1327 - accuracy: 0.9380\n",
            "Epoch 22/50\n",
            "1172/1172 - 1s - loss: 0.1303 - accuracy: 0.9389\n",
            "Epoch 23/50\n",
            "1172/1172 - 1s - loss: 0.1283 - accuracy: 0.9396\n",
            "Epoch 24/50\n",
            "1172/1172 - 1s - loss: 0.1264 - accuracy: 0.9401\n",
            "Epoch 25/50\n",
            "1172/1172 - 1s - loss: 0.1250 - accuracy: 0.9412\n",
            "Epoch 26/50\n",
            "1172/1172 - 1s - loss: 0.1231 - accuracy: 0.9410\n",
            "Epoch 27/50\n",
            "1172/1172 - 1s - loss: 0.1221 - accuracy: 0.9408\n",
            "Epoch 28/50\n",
            "1172/1172 - 1s - loss: 0.1203 - accuracy: 0.9422\n",
            "Epoch 29/50\n",
            "1172/1172 - 1s - loss: 0.1194 - accuracy: 0.9419\n",
            "Epoch 30/50\n",
            "1172/1172 - 1s - loss: 0.1177 - accuracy: 0.9430\n",
            "Epoch 31/50\n",
            "1172/1172 - 1s - loss: 0.1171 - accuracy: 0.9430\n",
            "Epoch 32/50\n",
            "1172/1172 - 1s - loss: 0.1156 - accuracy: 0.9435\n",
            "Epoch 33/50\n",
            "1172/1172 - 1s - loss: 0.1140 - accuracy: 0.9429\n",
            "Epoch 34/50\n",
            "1172/1172 - 1s - loss: 0.1136 - accuracy: 0.9440\n",
            "Epoch 35/50\n",
            "1172/1172 - 1s - loss: 0.1121 - accuracy: 0.9441\n",
            "Epoch 36/50\n",
            "1172/1172 - 1s - loss: 0.1113 - accuracy: 0.9447\n",
            "Epoch 37/50\n",
            "1172/1172 - 1s - loss: 0.1107 - accuracy: 0.9449\n",
            "Epoch 38/50\n",
            "1172/1172 - 1s - loss: 0.1091 - accuracy: 0.9453\n",
            "Epoch 39/50\n",
            "1172/1172 - 1s - loss: 0.1086 - accuracy: 0.9466\n",
            "Epoch 40/50\n",
            "1172/1172 - 1s - loss: 0.1059 - accuracy: 0.9485\n",
            "Epoch 41/50\n",
            "1172/1172 - 1s - loss: 0.1061 - accuracy: 0.9483\n",
            "Epoch 42/50\n",
            "1172/1172 - 1s - loss: 0.1045 - accuracy: 0.9494\n",
            "Epoch 43/50\n",
            "1172/1172 - 1s - loss: 0.1035 - accuracy: 0.9489\n",
            "Epoch 44/50\n",
            "1172/1172 - 1s - loss: 0.1057 - accuracy: 0.9493\n",
            "Epoch 45/50\n",
            "1172/1172 - 1s - loss: 0.1027 - accuracy: 0.9505\n",
            "Epoch 46/50\n",
            "1172/1172 - 1s - loss: 0.1016 - accuracy: 0.9506\n",
            "Epoch 47/50\n",
            "1172/1172 - 1s - loss: 0.1012 - accuracy: 0.9514\n",
            "Epoch 48/50\n",
            "1172/1172 - 1s - loss: 0.1005 - accuracy: 0.9521\n",
            "Epoch 49/50\n",
            "1172/1172 - 1s - loss: 0.0989 - accuracy: 0.9529\n",
            "Epoch 50/50\n",
            "1172/1172 - 1s - loss: 0.1004 - accuracy: 0.9509\n",
            "confusion matrix: on test data set\n",
            "[[5882  303]\n",
            " [ 334 5981]]\n",
            "errorRate 0.051\n",
            "N=500 : experiment_type: random_roads  road_input_type: vibration\n",
            "========== 4 out of 4 replications========\n",
            "The average error rate of 4 replications is:\n",
            "0.04046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEYhRq-ZWNxx"
      },
      "source": [
        "# Result Table\n",
        "\n",
        "Results for 3 models with different parameters (4 replications)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLJpnD2KXhmC"
      },
      "source": [
        "|ML algorithm|N runs|experiment type|observation type|error rates|result|\n",
        "|--- |--- |--- |--- |--- |--- |\n",
        "|KNN|100|random roads|road input|0.03400|success|\n",
        "|KNN|200|random roads|road input|0.02800|success|\n",
        "|KNN|200|one standard road|road input|0.00000|success|\n",
        "|KNN|200|random roads|in vehicle vibration|0.04550|success|\n",
        "|KNN|200|one standard road|in vehicle vibration|0.00000|success|\n",
        "|KNN|500|random roads|road input|0.01910|success|\n",
        "|Naive Bayes|200|random roads|road input|0.02650|success|\n",
        "|Naive Bayes|200|one standard road|in vehicle vibration|0.00000|success|\n",
        "|Naive Bayes|200|random roads|in vehicle vibration|0.05700|success|\n",
        "|Naive Bayes|1000|random roads|road input|0.01450|success|\n",
        "|MLP(20,5)|200|random roads|road input|0.00605|success|\n",
        "|MLP(20,5)|500|random roads|road input|0.00584|success|\n",
        "|MLP(20,5)|1000|random roads|road input|0.00419|success|\n",
        "|MLP(20,5)|500|one standard road|road input|0.00024|success|\n",
        "|MLP(20,5)|500|one standard road|in vehicle vibration|0.00000|success|\n",
        "|MLP(20,5)|500|random roads|in vehicle vibration|0.04046|success|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzNgtdssXikE"
      },
      "source": [
        "With the 20% threshold of an error rate, all cases with three models show successful results. \n",
        "\n",
        "### 1. K-Nearest Neighbour (KNN):\n",
        "KNN is a non-parametric algorithm. So it does not make any assumption on the data distribution. The main parameter it uses is the number of nearest neighbours. Objects are classified based on the most common class among the neighbours by their spacial distances (Similarity). \n",
        "\n",
        "So it has the advantage of easy implementation and it does not need to train some parameters. Very effective to noisy data (with random noise inputs from roads), and a big dataset (in this case we have 50k rows). \n",
        "\n",
        "However, it has the disadvantages that k value needs to be determined by a human, and the computation cost would get much higher as the number of features gets more.\n",
        "\n",
        "### 2. Naive Bayes Classifier\n",
        "It is naive because it assumes simply that every attribute is conditionally independent to each other.\n",
        "$$\n",
        "P(c|X) = P(x_1 | c) \\times P(x_2 | c) \\times \\cdots \\times P(x_n | c) \\times P(c)\n",
        "$$\n"
      ]
    }
  ]
}