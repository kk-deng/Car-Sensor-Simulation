{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Pitstop2.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YV07HtF4RJf",
        "outputId": "1d5681cd-0456-42c4-edaf-afc4306bd052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#define _FILE_SPECS \"-rw-r--r-- 1 chris 8007 Mar 25 12:33 cartsim_data.py\"\n",
        "#define _MAGIC_NUMBER 1147484068\n",
        "import numpy as np\n",
        "import math, os,   sys,  time\n",
        "from time import gmtime, strftime\n",
        "# from logger import logger\n",
        "from datetime import date, datetime, timezone\n",
        "import statistics as st\n",
        "import random as rn\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import random as rnn\n",
        " \n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "\n",
        "#equations\n",
        "# M \\ddot P = - C( X - X_0)  - D \\dot X\n",
        "#  P = X  + Z(Y(t))\n",
        "#  Y(t)= vt\n",
        "\n",
        "#  v=60km/hour = 16.666 m / sec\n",
        "#\n",
        "#  M= 1000kg\n",
        "#  X_0 =  5cm\n",
        "#  C spring const so 1000kg @ 10 m/sec^2 gives 5 cm ie\n",
        "#    =   5 x 10e-06\n",
        "#  X roughly +- 10cm\n",
        "#  road 3 components period   1 sec, 2 sec, 4 sec (random amplitude)\n",
        "#  sin(Y/(16.666)),  cos(Y/(16.666)), sin(Y/(2*16.66)), cos(Y/(2*16.66))\n",
        "#  choose D0 to efold in 1 second ie. D/2M = 1.0 --> D=2000\n",
        "#  too small is 'bad'\n",
        "#  choose sampling rate @ 4 Hz\n",
        "#  magnitude road = +- 5 max * sin( Y / 16.66 m)\n",
        "\n",
        "#  10 minute samples = 600 x 4 points @ 4 Hz\n",
        "#\n",
        "\n",
        "def Zbase ( trigtype, period, K, Y):\n",
        "    \n",
        "    if trigtype=='sin':\n",
        "        return math.sin( K * period * Y)\n",
        "    if trigtype=='cos':\n",
        "        return math.cos( K * period * Y)\n",
        "    \n",
        "def Zbaseddot ( trigtype, period, K, Y, v):\n",
        "    \n",
        "#     d^2/dt^ (VT)=0\n",
        "    if trigtype=='sin':\n",
        "        return -math.cos( K * period * Y) * v * v * (K /period) * (K/period)\n",
        "    if trigtype=='cos':\n",
        "        return -math.sin( K * period * Y) * v * v * (K /period) * (K/period)\n",
        "    \n",
        "def Xdot(Xn, Xnm1, dT):\n",
        "    return (Xn - Xnm1)/dT\n",
        "\n",
        "def Xddot(Xn, Xnm1, Xnm2, dT):\n",
        "    return (Xn - 2 * Xnm1  + Xnm2)/(dT * dT)\n",
        "\n",
        "def getXnp1(LHS, M, D, C, Xn, Xnm1, dT):\n",
        "# solve for Xnp1\n",
        "#  LHS = M(Xnp1 - 2 Xn + Xnm1)/delT^2 + D(Xnp1 - Xnm1)/2delT + C Xn\n",
        "  \n",
        "    rval = (LHS * dT * dT - (M - D * dT/2) * Xnm1  + (2 *M - C * dT * dT) * Xn  )/(M + D * dT/2) \n",
        "    \n",
        "    lv = M* (rval - 2 * Xn + Xnm1)/(dT * dT) + D* (rval - Xnm1)/(2*dT) + C * Xn\n",
        "    \n",
        "#    print(\"check %f = %f\" % (LHS,lv))\n",
        "          \n",
        "    return  rval\n",
        "\n",
        "def getLHSval(Zddval, Ms, Vs, Cs, X0s):\n",
        "# Cs * X0 =spring force\n",
        "    return - Ms * Zddval + Cs * X0s\n",
        "\n",
        "def zRoad(coeffs, v, Y, period, maxfreq):\n",
        "    \n",
        "    zR =0\n",
        "   \n",
        "    if maxfreq >= 0.5:\n",
        "       zR = coeffs[0]* Zbaseddot('cos', period, 0.5, Y, v) + zR\n",
        "       zR = coeffs[1]* Zbaseddot('sin', period, 0.5, Y, v) + zR\n",
        "\n",
        "    if maxfreq >= 1.0:\n",
        "       zR = coeffs[2]* Zbaseddot('cos', period, 1.0, Y, v) + zR\n",
        "       zR = coeffs[3]* Zbaseddot('sin', period, 1.0, Y, v) + zR\n",
        "    \n",
        "    if maxfreq >=2.0:\n",
        "       zR = coeffs[4]* Zbaseddot('cos', period, 2.0, Y, v) + zR\n",
        "       zR = coeffs[5]* Zbaseddot('sin', period, 2.0, Y, v) + zR\n",
        "       \n",
        "    if maxfreq >=4.0:\n",
        "       zR = coeffs[6]* Zbaseddot('cos', period, 4.0, Y, v) + zR\n",
        "       zR = coeffs[7]* Zbaseddot('sin', period, 4.0, Y, v) + zR\n",
        "    \n",
        "    return zR\n",
        "\n",
        "def  getRandomCoeffs(N):\n",
        "    \n",
        "     ampChoice=[0.01, 0.02, 0.025, 0.03, 0.035]\n",
        "     coeffs=[]\n",
        "\n",
        "     for i in range(0,N):\n",
        "          rAmpl1=rn.choice(ampChoice) \n",
        "#          rAmpl1=rAmpl\n",
        "          coeffs.append(rAmpl1)\n",
        "          \n",
        "     return coeffs\n",
        " \n",
        " \n",
        "\n",
        "def  compute_sim(M, D0, V, C, X0, delT, period, maxfreq, coeffs, topsample):\n",
        "    \n",
        "    Y=0\n",
        "# start with spring at rest\n",
        "    Xnp1=X0\n",
        "    Xn=X0\n",
        "    Xnm1=X0\n",
        "\n",
        "\n",
        "    springPos=[]\n",
        "    timeVal=[]\n",
        "    roadSurf=[]\n",
        "    \n",
        "     \n",
        "    for i in range(0, topsample):\n",
        "    \n",
        "        t= i * delT\n",
        "        timeVal.append(t)\n",
        "#        print(\"                T=%8.2f\" % t)\n",
        "    \n",
        "        Y= V * t  \n",
        "    \n",
        "        Zddval= zRoad(coeffs, V, Y, period, maxfreq)\n",
        "    \n",
        "#        print(\"Zddval %f\" % Zddval)\n",
        "    \n",
        "# LHS= -M (ddot (Z(Y))) + CX0\n",
        "        LHS= getLHSval(Zddval, M, V, C, X0)\n",
        "        roadSurf.append(LHS)\n",
        "    \n",
        "        Xnp1 = getXnp1(LHS, M, D0, C, Xn, Xnm1, delT)\n",
        "        springPos.append(Xnp1)\n",
        "    \n",
        "#        print(\"Xnp1 %8.3f  Xn %8.3f Xnm1 %8.3f\" % (Xnp1, Xn, Xnm1))\n",
        "    \n",
        "        Xnm1=Xn\n",
        "        Xn=Xnp1\n",
        "        \n",
        "    return [roadSurf, timeVal, springPos, t]\n",
        "\n",
        "def add_sample(M, D0, V, C, X0, delT, period, maxfreq, botsample, topsample, lval,Ncoeffs, Rcoeffs, road_input_type):\n",
        " # compute discriminant\n",
        "    disc= D0*D0 - 4 * M * C   \n",
        "    \n",
        "    [roadSurf, timeVals, springPos, tmax]= compute_sim(M, D0, V, C, X0, delT, period, maxfreq, Rcoeffs, topsample)\n",
        "\n",
        "    yval=[]\n",
        "    Xdat=[]\n",
        "\n",
        "#    print(\"sample D0=%d label=%s\" % (D0,lval )) \n",
        "#    print(\"D=%12.2f disc  %12.2f   maxfreq= %f\" % (D0, disc,   maxfreq))\n",
        "#    if disc < 0:\n",
        "#        print(\"sqrt = %f\" % math.sqrt(-disc))\n",
        " \n",
        "# assume botsample is > 3\n",
        "\n",
        "    if road_input_type=='vibration':\n",
        "        tupleLen=8\n",
        "    elif road_input_type=='surface':\n",
        "        tupleLen=2\n",
        "    else:\n",
        "        print(\"unknown road_type %s\" % road_type)\n",
        "        tupleLen=2\n",
        " \n",
        "# in this case include roadSurf = LHS as variable\n",
        "    xnorm=10000 \n",
        "    for i in range(botsample,topsample):\n",
        "        if tupleLen==2:\n",
        "# road input\n",
        "           Xdat.append([roadSurf[i]/xnorm, springPos[i-2], springPos[i-1], springPos[i]])\n",
        "# in vehicle vibration\n",
        "        elif tupleLen==5:\n",
        "           Xdat.append([springPos[i-5], springPos[i-4], springPos[i-3], springPos[i-2], springPos[i-1], springPos[i]])\n",
        "#  in vehicle vibration (long)\n",
        "        elif tupleLen==8:\n",
        "           Xdat.append([springPos[-8], springPos[-7], springPos[-6], springPos[i-5], springPos[i-4], springPos[i-3], springPos[i-2], springPos[i-1], springPos[i]])\n",
        "        else:\n",
        "            print(\"Unsupported tupleLen %d\" % tupleLen)\n",
        "            return [[],[]]\n",
        "        \n",
        "        yval.append(lval)\n",
        " \n",
        "    return [Xdat, yval]\n",
        "    \n",
        "\n",
        "# mass    \n",
        "M=2000 \n",
        "#   5cm compression\n",
        "X0= 0.05\n",
        "# spring const    \n",
        "\n",
        "C= 0.6  * 10e+04\n",
        "delT=0.25\n",
        "# interesting values 500, 5000, 15000, 25000\n",
        " \n",
        "# damping\n",
        "Dvalues=[5000, 5500, 6000, 6500, 4500, 4000, 3500, 500, 600, 700, 800, 400, 300, 200]\n",
        "\n",
        "LABELvalues=['good','good', 'good', 'good', 'good','good','good','bad','bad','bad','bad','bad','bad','bad']\n",
        "\n",
        "dindexlist=[x for x in range(0,14)]\n",
        "\n",
        " \n",
        "# car moves at 16.66 m/s\n",
        "V= 16.66 \n",
        "period= 16.66 \n",
        "maxfreq=4.0\n",
        " \n",
        "botsample=400 \n",
        "topsample=500\n",
        "Ncoeffs=8\n",
        "\n",
        "X=[]\n",
        "y=[]\n",
        "ngood=0\n",
        "nbad=0\n",
        "\n",
        "nruns=500\n",
        "testfraction=0.3\n",
        "experiment_type='random_roads'\n",
        "#experiment_type='standard_road'\n",
        "\n",
        "# initialize road\n",
        "Rcoeffs=getRandomCoeffs(Ncoeffs) \n",
        "\n",
        "ldindexlist=[x for x in range(0, 100* nruns)]\n",
        "\n",
        "for i in range(0,nruns):\n",
        "    \n",
        "           dindex=rn.choice(dindexlist)\n",
        "\n",
        "           D0=Dvalues[dindex]\n",
        "           labval=LABELvalues[dindex]\n",
        "    \n",
        " \n",
        "           if experiment_type=='random_roads':\n",
        "              Rcoeffs=getRandomCoeffs(Ncoeffs)\n",
        "              \n",
        "\n",
        " \n",
        "#  For  in vehicle vibration road_input_type='vibration'\n",
        "#  For  road input set road_input_type='surface'\n",
        "           \n",
        "           road_input_type='surface'\n",
        " \n",
        "           [Xdat, yval]= add_sample(M, D0, V, C, X0, delT, period, maxfreq, botsample, topsample, labval,Ncoeffs, Rcoeffs, road_input_type)\n",
        "           \n",
        "# [roadsurf, Xn-2, Xn-1, Xn]\n",
        "           if yval[0]=='good':\n",
        "               ngood+=1\n",
        "           if yval[0]=='bad':\n",
        "               nbad+=1\n",
        " \n",
        "           for j in range(0, len(Xdat)):\n",
        "                X.append(Xdat[j])\n",
        "                y.append(yval[j])\n",
        "                \n",
        "\n",
        "print(\"shuffling %d entries\" % len(ldindexlist))\n",
        "rn.shuffle(ldindexlist)\n",
        "# sanity check\n",
        "print(ldindexlist[0:10])\n",
        "\n",
        "X_rn=[]\n",
        "y_rn=[]\n",
        "\n",
        "for i in range(0, len(X)):\n",
        "    X_rn.append(X[ldindexlist[i]])\n",
        "    y_rn.append(y[ldindexlist[i]])\n",
        "    \n",
        "    \n",
        "           \n",
        "print(\"made %d samples with botsample %d topsample %d\" % (nruns,botsample, topsample))\n",
        "print(\"maxfreq= %8.2f M= %8.2f V=%8.2f C=%8.2f\" % (maxfreq, M, V, C))\n",
        "\n",
        "totalN=len(X)\n",
        "print(\"Total samples %d good runs %d bad runs %d\" % (totalN, ngood, nbad))\n",
        "\n",
        "#print(Xdat)\n",
        "\n",
        "print (strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        " \n",
        "\n",
        " \n",
        "    \n",
        "    \n",
        "    \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shuffling 50000 entries\n",
            "[26676, 22356, 46592, 18488, 47457, 14013, 39138, 25667, 35800, 40664]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 255 bad runs 245\n",
            "2021-05-20 02:17:34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFixtxd84RKP"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rn, y_rn, random_state=42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TInQeO0k4RKS",
        "outputId": "3fcebbdd-801f-40cc-b25b-86582378eaf0"
      },
      "source": [
        "print(len(X_train), len(y_train))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37500 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeuSiJPR4RKT",
        "outputId": "c5b79a6a-5889-42d3-a2f7-20d5c96e4553"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "X_train_scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.27262918, -0.11483383,  0.94769836,  0.98701581],\n",
              "       [ 0.9108106 ,  0.5772926 ,  1.00514885,  0.41176585],\n",
              "       [-0.67410636,  1.53909548,  0.3360679 , -1.37985839],\n",
              "       ...,\n",
              "       [-0.17469505,  0.26375549,  0.21184107, -0.23138801],\n",
              "       [-1.20669643, -0.04664252, -1.07631521, -0.86824393],\n",
              "       [ 0.66724922,  0.83172868,  0.94539515, -0.08178625]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgP1wyiX4RKU",
        "outputId": "a488ed90-56bc-482e-fac3-a56ee6f950d1"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7FSbHjd4RKV",
        "outputId": "f483d737-6e06-4816-92ca-bb0f0b3cca72"
      },
      "source": [
        "model.score(X_test_scaled, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.52888"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RK2pT7D4RKW",
        "outputId": "3c71b15d-7cda-4991-a802-c9436b7a1f45"
      },
      "source": [
        "model.score(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5303733333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k5MyPu74RKX",
        "outputId": "af05dc47-b56d-43f1-e134-ec2d88ea8d1e"
      },
      "source": [
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "knn.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQjq939p4RKY",
        "outputId": "dab4e6f5-efd7-4f61-fe59-65bbdb2d3ada"
      },
      "source": [
        "knn.score(X_test_scaled, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97912"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmHoSdJf4RKa",
        "outputId": "6d6363b0-e68a-4b44-cac5-c1ec2896cb90"
      },
      "source": [
        "knn.score(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9918133333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6Q1J0RQ4RKb",
        "outputId": "9e24291c-568d-4145-9ee9-a7f3a90657c8"
      },
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0krP1_TQ4RKb",
        "outputId": "251e848f-f4b3-4499-bd37-0b4b0f6e4d1e"
      },
      "source": [
        "rf.score(X_test_scaled, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpBPp6Xo4RKc",
        "outputId": "e402affe-9a96-4923-a446-4c7d2766b5db"
      },
      "source": [
        "knn.score(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9918133333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blXHIrju4ctv"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGNnNlIlkT49",
        "outputId": "adec0efc-dda8-4b68-a452-4b021e0a43bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confirm the unique label values\n",
        "unique = list(dict.fromkeys(y_rn))\n",
        "unique"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good', 'bad']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJVz2eBXm0mJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rn, y_rn, random_state=42)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cozq1bS8m36F",
        "outputId": "c7db3717-65d5-4f7e-aa74-143e6577850b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "X_train_scaled"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.29600742, -0.39362977, -1.24455271, -0.7831079 ],\n",
              "       [-0.61458652,  1.71717352,  0.1736151 , -1.45745833],\n",
              "       [ 1.8550103 ,  0.08350871,  1.39014717,  1.40001554],\n",
              "       ...,\n",
              "       [ 0.05109224, -0.4201084 , -0.11939833,  0.20715919],\n",
              "       [ 1.3025157 , -0.19111097,  1.05634924,  0.9880186 ],\n",
              "       [-0.75827418,  1.16697152, -0.18735799, -1.26352545]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCXlZZyN4RKc",
        "outputId": "0d662843-734e-4700-9066-bb4ba1fdd8e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Transform y values\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_model = LabelEncoder()\n",
        "label_model.fit(y_train)\n",
        "\n",
        "y_train_encoded = label_model.transform(y_train)\n",
        "y_test_encoded = label_model.transform(y_test)\n",
        "y_train_encoded"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlOkEr3Z4RKd",
        "outputId": "46354903-a3f7-4403-d2ab-d29f0b538009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Convert to categorical data\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "y_test_categorical = to_categorical(y_test_encoded)\n",
        "y_train_categorical"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnH7nGel5HVc",
        "outputId": "748e1eeb-06d9-41e6-e918-6972abe20423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Building NN model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=4, activation=\"relu\", input_dim=4))\n",
        "model.add(Dense(units=3, activation=\"softmax\"))\n",
        "model.add(Dense(units=3, activation=\"relu\"))\n",
        "model.add(Dense(units=2, activation=\"softmax\"))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 3)                 15        \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 2)                 8         \n",
            "=================================================================\n",
            "Total params: 55\n",
            "Trainable params: 55\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IerFuUz-5P5G",
        "outputId": "8a31a664-2eb5-4e92-9af2-13b00f534a71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fitting model\n",
        "model.fit(X_train_scaled, y_train_categorical, epochs=200, shuffle=True, verbose=2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1172/1172 - 1s - loss: 0.6761 - accuracy: 0.5650\n",
            "Epoch 2/200\n",
            "1172/1172 - 1s - loss: 0.4312 - accuracy: 0.7973\n",
            "Epoch 3/200\n",
            "1172/1172 - 1s - loss: 0.2355 - accuracy: 0.9085\n",
            "Epoch 4/200\n",
            "1172/1172 - 1s - loss: 0.1891 - accuracy: 0.9178\n",
            "Epoch 5/200\n",
            "1172/1172 - 1s - loss: 0.1667 - accuracy: 0.9241\n",
            "Epoch 6/200\n",
            "1172/1172 - 1s - loss: 0.1492 - accuracy: 0.9291\n",
            "Epoch 7/200\n",
            "1172/1172 - 1s - loss: 0.1344 - accuracy: 0.9341\n",
            "Epoch 8/200\n",
            "1172/1172 - 1s - loss: 0.1235 - accuracy: 0.9403\n",
            "Epoch 9/200\n",
            "1172/1172 - 1s - loss: 0.1138 - accuracy: 0.9438\n",
            "Epoch 10/200\n",
            "1172/1172 - 1s - loss: 0.1051 - accuracy: 0.9472\n",
            "Epoch 11/200\n",
            "1172/1172 - 1s - loss: 0.0969 - accuracy: 0.9507\n",
            "Epoch 12/200\n",
            "1172/1172 - 1s - loss: 0.0894 - accuracy: 0.9553\n",
            "Epoch 13/200\n",
            "1172/1172 - 1s - loss: 0.0829 - accuracy: 0.9586\n",
            "Epoch 14/200\n",
            "1172/1172 - 1s - loss: 0.0763 - accuracy: 0.9624\n",
            "Epoch 15/200\n",
            "1172/1172 - 1s - loss: 0.0709 - accuracy: 0.9652\n",
            "Epoch 16/200\n",
            "1172/1172 - 1s - loss: 0.0656 - accuracy: 0.9682\n",
            "Epoch 17/200\n",
            "1172/1172 - 1s - loss: 0.0605 - accuracy: 0.9699\n",
            "Epoch 18/200\n",
            "1172/1172 - 1s - loss: 0.0561 - accuracy: 0.9723\n",
            "Epoch 19/200\n",
            "1172/1172 - 1s - loss: 0.0519 - accuracy: 0.9756\n",
            "Epoch 20/200\n",
            "1172/1172 - 1s - loss: 0.0480 - accuracy: 0.9775\n",
            "Epoch 21/200\n",
            "1172/1172 - 1s - loss: 0.0440 - accuracy: 0.9802\n",
            "Epoch 22/200\n",
            "1172/1172 - 1s - loss: 0.0418 - accuracy: 0.9809\n",
            "Epoch 23/200\n",
            "1172/1172 - 1s - loss: 0.0385 - accuracy: 0.9830\n",
            "Epoch 24/200\n",
            "1172/1172 - 1s - loss: 0.0363 - accuracy: 0.9840\n",
            "Epoch 25/200\n",
            "1172/1172 - 1s - loss: 0.0345 - accuracy: 0.9848\n",
            "Epoch 26/200\n",
            "1172/1172 - 1s - loss: 0.0327 - accuracy: 0.9851\n",
            "Epoch 27/200\n",
            "1172/1172 - 1s - loss: 0.0308 - accuracy: 0.9866\n",
            "Epoch 28/200\n",
            "1172/1172 - 1s - loss: 0.0299 - accuracy: 0.9872\n",
            "Epoch 29/200\n",
            "1172/1172 - 1s - loss: 0.0283 - accuracy: 0.9878\n",
            "Epoch 30/200\n",
            "1172/1172 - 1s - loss: 0.0275 - accuracy: 0.9878\n",
            "Epoch 31/200\n",
            "1172/1172 - 1s - loss: 0.0267 - accuracy: 0.9876\n",
            "Epoch 32/200\n",
            "1172/1172 - 1s - loss: 0.0259 - accuracy: 0.9888\n",
            "Epoch 33/200\n",
            "1172/1172 - 1s - loss: 0.0252 - accuracy: 0.9885\n",
            "Epoch 34/200\n",
            "1172/1172 - 1s - loss: 0.0245 - accuracy: 0.9890\n",
            "Epoch 35/200\n",
            "1172/1172 - 1s - loss: 0.0241 - accuracy: 0.9898\n",
            "Epoch 36/200\n",
            "1172/1172 - 1s - loss: 0.0227 - accuracy: 0.9901\n",
            "Epoch 37/200\n",
            "1172/1172 - 1s - loss: 0.0230 - accuracy: 0.9897\n",
            "Epoch 38/200\n",
            "1172/1172 - 1s - loss: 0.0224 - accuracy: 0.9906\n",
            "Epoch 39/200\n",
            "1172/1172 - 1s - loss: 0.0220 - accuracy: 0.9896\n",
            "Epoch 40/200\n",
            "1172/1172 - 1s - loss: 0.0215 - accuracy: 0.9905\n",
            "Epoch 41/200\n",
            "1172/1172 - 1s - loss: 0.0208 - accuracy: 0.9909\n",
            "Epoch 42/200\n",
            "1172/1172 - 1s - loss: 0.0210 - accuracy: 0.9905\n",
            "Epoch 43/200\n",
            "1172/1172 - 1s - loss: 0.0211 - accuracy: 0.9905\n",
            "Epoch 44/200\n",
            "1172/1172 - 1s - loss: 0.0201 - accuracy: 0.9910\n",
            "Epoch 45/200\n",
            "1172/1172 - 1s - loss: 0.0200 - accuracy: 0.9905\n",
            "Epoch 46/200\n",
            "1172/1172 - 1s - loss: 0.0209 - accuracy: 0.9907\n",
            "Epoch 47/200\n",
            "1172/1172 - 1s - loss: 0.0197 - accuracy: 0.9907\n",
            "Epoch 48/200\n",
            "1172/1172 - 1s - loss: 0.0196 - accuracy: 0.9912\n",
            "Epoch 49/200\n",
            "1172/1172 - 1s - loss: 0.0195 - accuracy: 0.9912\n",
            "Epoch 50/200\n",
            "1172/1172 - 1s - loss: 0.0191 - accuracy: 0.9914\n",
            "Epoch 51/200\n",
            "1172/1172 - 1s - loss: 0.0187 - accuracy: 0.9916\n",
            "Epoch 52/200\n",
            "1172/1172 - 1s - loss: 0.0181 - accuracy: 0.9917\n",
            "Epoch 53/200\n",
            "1172/1172 - 1s - loss: 0.0188 - accuracy: 0.9916\n",
            "Epoch 54/200\n",
            "1172/1172 - 1s - loss: 0.0181 - accuracy: 0.9919\n",
            "Epoch 55/200\n",
            "1172/1172 - 1s - loss: 0.0176 - accuracy: 0.9918\n",
            "Epoch 56/200\n",
            "1172/1172 - 1s - loss: 0.0185 - accuracy: 0.9917\n",
            "Epoch 57/200\n",
            "1172/1172 - 1s - loss: 0.0179 - accuracy: 0.9917\n",
            "Epoch 58/200\n",
            "1172/1172 - 1s - loss: 0.0189 - accuracy: 0.9912\n",
            "Epoch 59/200\n",
            "1172/1172 - 1s - loss: 0.0171 - accuracy: 0.9929\n",
            "Epoch 60/200\n",
            "1172/1172 - 1s - loss: 0.0180 - accuracy: 0.9922\n",
            "Epoch 61/200\n",
            "1172/1172 - 1s - loss: 0.0171 - accuracy: 0.9921\n",
            "Epoch 62/200\n",
            "1172/1172 - 1s - loss: 0.0170 - accuracy: 0.9920\n",
            "Epoch 63/200\n",
            "1172/1172 - 1s - loss: 0.0172 - accuracy: 0.9923\n",
            "Epoch 64/200\n",
            "1172/1172 - 1s - loss: 0.0181 - accuracy: 0.9918\n",
            "Epoch 65/200\n",
            "1172/1172 - 1s - loss: 0.0168 - accuracy: 0.9924\n",
            "Epoch 66/200\n",
            "1172/1172 - 1s - loss: 0.0161 - accuracy: 0.9930\n",
            "Epoch 67/200\n",
            "1172/1172 - 1s - loss: 0.0167 - accuracy: 0.9923\n",
            "Epoch 68/200\n",
            "1172/1172 - 1s - loss: 0.0164 - accuracy: 0.9928\n",
            "Epoch 69/200\n",
            "1172/1172 - 1s - loss: 0.0158 - accuracy: 0.9926\n",
            "Epoch 70/200\n",
            "1172/1172 - 1s - loss: 0.0177 - accuracy: 0.9913\n",
            "Epoch 71/200\n",
            "1172/1172 - 1s - loss: 0.0160 - accuracy: 0.9928\n",
            "Epoch 72/200\n",
            "1172/1172 - 1s - loss: 0.0150 - accuracy: 0.9933\n",
            "Epoch 73/200\n",
            "1172/1172 - 1s - loss: 0.0158 - accuracy: 0.9932\n",
            "Epoch 74/200\n",
            "1172/1172 - 1s - loss: 0.0150 - accuracy: 0.9932\n",
            "Epoch 75/200\n",
            "1172/1172 - 1s - loss: 0.0163 - accuracy: 0.9928\n",
            "Epoch 76/200\n",
            "1172/1172 - 1s - loss: 0.0146 - accuracy: 0.9934\n",
            "Epoch 77/200\n",
            "1172/1172 - 1s - loss: 0.0151 - accuracy: 0.9930\n",
            "Epoch 78/200\n",
            "1172/1172 - 1s - loss: 0.0150 - accuracy: 0.9931\n",
            "Epoch 79/200\n",
            "1172/1172 - 1s - loss: 0.0148 - accuracy: 0.9934\n",
            "Epoch 80/200\n",
            "1172/1172 - 1s - loss: 0.0159 - accuracy: 0.9928\n",
            "Epoch 81/200\n",
            "1172/1172 - 1s - loss: 0.0152 - accuracy: 0.9931\n",
            "Epoch 82/200\n",
            "1172/1172 - 1s - loss: 0.0146 - accuracy: 0.9933\n",
            "Epoch 83/200\n",
            "1172/1172 - 1s - loss: 0.0141 - accuracy: 0.9937\n",
            "Epoch 84/200\n",
            "1172/1172 - 1s - loss: 0.0157 - accuracy: 0.9925\n",
            "Epoch 85/200\n",
            "1172/1172 - 1s - loss: 0.0137 - accuracy: 0.9944\n",
            "Epoch 86/200\n",
            "1172/1172 - 1s - loss: 0.0148 - accuracy: 0.9926\n",
            "Epoch 87/200\n",
            "1172/1172 - 1s - loss: 0.0148 - accuracy: 0.9932\n",
            "Epoch 88/200\n",
            "1172/1172 - 1s - loss: 0.0136 - accuracy: 0.9940\n",
            "Epoch 89/200\n",
            "1172/1172 - 1s - loss: 0.0139 - accuracy: 0.9938\n",
            "Epoch 90/200\n",
            "1172/1172 - 1s - loss: 0.0151 - accuracy: 0.9930\n",
            "Epoch 91/200\n",
            "1172/1172 - 1s - loss: 0.0134 - accuracy: 0.9942\n",
            "Epoch 92/200\n",
            "1172/1172 - 1s - loss: 0.0140 - accuracy: 0.9937\n",
            "Epoch 93/200\n",
            "1172/1172 - 1s - loss: 0.0152 - accuracy: 0.9931\n",
            "Epoch 94/200\n",
            "1172/1172 - 1s - loss: 0.0141 - accuracy: 0.9934\n",
            "Epoch 95/200\n",
            "1172/1172 - 1s - loss: 0.0144 - accuracy: 0.9937\n",
            "Epoch 96/200\n",
            "1172/1172 - 1s - loss: 0.0142 - accuracy: 0.9937\n",
            "Epoch 97/200\n",
            "1172/1172 - 1s - loss: 0.0138 - accuracy: 0.9938\n",
            "Epoch 98/200\n",
            "1172/1172 - 1s - loss: 0.0140 - accuracy: 0.9937\n",
            "Epoch 99/200\n",
            "1172/1172 - 1s - loss: 0.0133 - accuracy: 0.9941\n",
            "Epoch 100/200\n",
            "1172/1172 - 1s - loss: 0.0138 - accuracy: 0.9937\n",
            "Epoch 101/200\n",
            "1172/1172 - 1s - loss: 0.0134 - accuracy: 0.9936\n",
            "Epoch 102/200\n",
            "1172/1172 - 1s - loss: 0.0137 - accuracy: 0.9937\n",
            "Epoch 103/200\n",
            "1172/1172 - 1s - loss: 0.0129 - accuracy: 0.9942\n",
            "Epoch 104/200\n",
            "1172/1172 - 1s - loss: 0.0136 - accuracy: 0.9939\n",
            "Epoch 105/200\n",
            "1172/1172 - 1s - loss: 0.0150 - accuracy: 0.9935\n",
            "Epoch 106/200\n",
            "1172/1172 - 1s - loss: 0.0129 - accuracy: 0.9940\n",
            "Epoch 107/200\n",
            "1172/1172 - 1s - loss: 0.0141 - accuracy: 0.9936\n",
            "Epoch 108/200\n",
            "1172/1172 - 1s - loss: 0.0135 - accuracy: 0.9941\n",
            "Epoch 109/200\n",
            "1172/1172 - 1s - loss: 0.0131 - accuracy: 0.9938\n",
            "Epoch 110/200\n",
            "1172/1172 - 1s - loss: 0.0132 - accuracy: 0.9940\n",
            "Epoch 111/200\n",
            "1172/1172 - 1s - loss: 0.0127 - accuracy: 0.9943\n",
            "Epoch 112/200\n",
            "1172/1172 - 1s - loss: 0.0139 - accuracy: 0.9938\n",
            "Epoch 113/200\n",
            "1172/1172 - 1s - loss: 0.0127 - accuracy: 0.9945\n",
            "Epoch 114/200\n",
            "1172/1172 - 1s - loss: 0.0135 - accuracy: 0.9938\n",
            "Epoch 115/200\n",
            "1172/1172 - 1s - loss: 0.0129 - accuracy: 0.9943\n",
            "Epoch 116/200\n",
            "1172/1172 - 1s - loss: 0.0129 - accuracy: 0.9943\n",
            "Epoch 117/200\n",
            "1172/1172 - 1s - loss: 0.0141 - accuracy: 0.9934\n",
            "Epoch 118/200\n",
            "1172/1172 - 1s - loss: 0.0123 - accuracy: 0.9943\n",
            "Epoch 119/200\n",
            "1172/1172 - 1s - loss: 0.0121 - accuracy: 0.9946\n",
            "Epoch 120/200\n",
            "1172/1172 - 1s - loss: 0.0141 - accuracy: 0.9941\n",
            "Epoch 121/200\n",
            "1172/1172 - 1s - loss: 0.0136 - accuracy: 0.9939\n",
            "Epoch 122/200\n",
            "1172/1172 - 1s - loss: 0.0128 - accuracy: 0.9944\n",
            "Epoch 123/200\n",
            "1172/1172 - 1s - loss: 0.0125 - accuracy: 0.9943\n",
            "Epoch 124/200\n",
            "1172/1172 - 1s - loss: 0.0129 - accuracy: 0.9941\n",
            "Epoch 125/200\n",
            "1172/1172 - 1s - loss: 0.0127 - accuracy: 0.9943\n",
            "Epoch 126/200\n",
            "1172/1172 - 1s - loss: 0.0121 - accuracy: 0.9947\n",
            "Epoch 127/200\n",
            "1172/1172 - 1s - loss: 0.0126 - accuracy: 0.9943\n",
            "Epoch 128/200\n",
            "1172/1172 - 1s - loss: 0.0134 - accuracy: 0.9939\n",
            "Epoch 129/200\n",
            "1172/1172 - 1s - loss: 0.0135 - accuracy: 0.9938\n",
            "Epoch 130/200\n",
            "1172/1172 - 1s - loss: 0.0113 - accuracy: 0.9951\n",
            "Epoch 131/200\n",
            "1172/1172 - 1s - loss: 0.0137 - accuracy: 0.9942\n",
            "Epoch 132/200\n",
            "1172/1172 - 1s - loss: 0.0116 - accuracy: 0.9949\n",
            "Epoch 133/200\n",
            "1172/1172 - 1s - loss: 0.0130 - accuracy: 0.9944\n",
            "Epoch 134/200\n",
            "1172/1172 - 1s - loss: 0.0130 - accuracy: 0.9947\n",
            "Epoch 135/200\n",
            "1172/1172 - 1s - loss: 0.0124 - accuracy: 0.9944\n",
            "Epoch 136/200\n",
            "1172/1172 - 1s - loss: 0.0120 - accuracy: 0.9944\n",
            "Epoch 137/200\n",
            "1172/1172 - 1s - loss: 0.0117 - accuracy: 0.9947\n",
            "Epoch 138/200\n",
            "1172/1172 - 1s - loss: 0.0135 - accuracy: 0.9940\n",
            "Epoch 139/200\n",
            "1172/1172 - 1s - loss: 0.0121 - accuracy: 0.9945\n",
            "Epoch 140/200\n",
            "1172/1172 - 1s - loss: 0.0128 - accuracy: 0.9947\n",
            "Epoch 141/200\n",
            "1172/1172 - 1s - loss: 0.0116 - accuracy: 0.9948\n",
            "Epoch 142/200\n",
            "1172/1172 - 1s - loss: 0.0120 - accuracy: 0.9946\n",
            "Epoch 143/200\n",
            "1172/1172 - 1s - loss: 0.0122 - accuracy: 0.9942\n",
            "Epoch 144/200\n",
            "1172/1172 - 1s - loss: 0.0122 - accuracy: 0.9943\n",
            "Epoch 145/200\n",
            "1172/1172 - 1s - loss: 0.0113 - accuracy: 0.9950\n",
            "Epoch 146/200\n",
            "1172/1172 - 1s - loss: 0.0124 - accuracy: 0.9944\n",
            "Epoch 147/200\n",
            "1172/1172 - 1s - loss: 0.0115 - accuracy: 0.9949\n",
            "Epoch 148/200\n",
            "1172/1172 - 1s - loss: 0.0124 - accuracy: 0.9946\n",
            "Epoch 149/200\n",
            "1172/1172 - 1s - loss: 0.0117 - accuracy: 0.9949\n",
            "Epoch 150/200\n",
            "1172/1172 - 1s - loss: 0.0123 - accuracy: 0.9945\n",
            "Epoch 151/200\n",
            "1172/1172 - 1s - loss: 0.0131 - accuracy: 0.9938\n",
            "Epoch 152/200\n",
            "1172/1172 - 1s - loss: 0.0109 - accuracy: 0.9951\n",
            "Epoch 153/200\n",
            "1172/1172 - 1s - loss: 0.0129 - accuracy: 0.9943\n",
            "Epoch 154/200\n",
            "1172/1172 - 1s - loss: 0.0127 - accuracy: 0.9948\n",
            "Epoch 155/200\n",
            "1172/1172 - 1s - loss: 0.0120 - accuracy: 0.9945\n",
            "Epoch 156/200\n",
            "1172/1172 - 1s - loss: 0.0121 - accuracy: 0.9947\n",
            "Epoch 157/200\n",
            "1172/1172 - 1s - loss: 0.0134 - accuracy: 0.9942\n",
            "Epoch 158/200\n",
            "1172/1172 - 1s - loss: 0.0117 - accuracy: 0.9949\n",
            "Epoch 159/200\n",
            "1172/1172 - 1s - loss: 0.0133 - accuracy: 0.9943\n",
            "Epoch 160/200\n",
            "1172/1172 - 1s - loss: 0.0114 - accuracy: 0.9945\n",
            "Epoch 161/200\n",
            "1172/1172 - 1s - loss: 0.0111 - accuracy: 0.9949\n",
            "Epoch 162/200\n",
            "1172/1172 - 1s - loss: 0.0116 - accuracy: 0.9950\n",
            "Epoch 163/200\n",
            "1172/1172 - 1s - loss: 0.0109 - accuracy: 0.9950\n",
            "Epoch 164/200\n",
            "1172/1172 - 1s - loss: 0.0115 - accuracy: 0.9947\n",
            "Epoch 165/200\n",
            "1172/1172 - 1s - loss: 0.0119 - accuracy: 0.9945\n",
            "Epoch 166/200\n",
            "1172/1172 - 1s - loss: 0.0119 - accuracy: 0.9947\n",
            "Epoch 167/200\n",
            "1172/1172 - 1s - loss: 0.0115 - accuracy: 0.9949\n",
            "Epoch 168/200\n",
            "1172/1172 - 1s - loss: 0.0111 - accuracy: 0.9948\n",
            "Epoch 169/200\n",
            "1172/1172 - 1s - loss: 0.0117 - accuracy: 0.9946\n",
            "Epoch 170/200\n",
            "1172/1172 - 1s - loss: 0.0115 - accuracy: 0.9954\n",
            "Epoch 171/200\n",
            "1172/1172 - 1s - loss: 0.0114 - accuracy: 0.9949\n",
            "Epoch 172/200\n",
            "1172/1172 - 1s - loss: 0.0120 - accuracy: 0.9945\n",
            "Epoch 173/200\n",
            "1172/1172 - 1s - loss: 0.0114 - accuracy: 0.9948\n",
            "Epoch 174/200\n",
            "1172/1172 - 1s - loss: 0.0118 - accuracy: 0.9948\n",
            "Epoch 175/200\n",
            "1172/1172 - 1s - loss: 0.0122 - accuracy: 0.9948\n",
            "Epoch 176/200\n",
            "1172/1172 - 1s - loss: 0.0116 - accuracy: 0.9953\n",
            "Epoch 177/200\n",
            "1172/1172 - 1s - loss: 0.0115 - accuracy: 0.9947\n",
            "Epoch 178/200\n",
            "1172/1172 - 1s - loss: 0.0114 - accuracy: 0.9947\n",
            "Epoch 179/200\n",
            "1172/1172 - 1s - loss: 0.0105 - accuracy: 0.9950\n",
            "Epoch 180/200\n",
            "1172/1172 - 1s - loss: 0.0115 - accuracy: 0.9949\n",
            "Epoch 181/200\n",
            "1172/1172 - 1s - loss: 0.0116 - accuracy: 0.9948\n",
            "Epoch 182/200\n",
            "1172/1172 - 1s - loss: 0.0126 - accuracy: 0.9944\n",
            "Epoch 183/200\n",
            "1172/1172 - 1s - loss: 0.0111 - accuracy: 0.9955\n",
            "Epoch 184/200\n",
            "1172/1172 - 1s - loss: 0.0115 - accuracy: 0.9949\n",
            "Epoch 185/200\n",
            "1172/1172 - 1s - loss: 0.0107 - accuracy: 0.9952\n",
            "Epoch 186/200\n",
            "1172/1172 - 1s - loss: 0.0115 - accuracy: 0.9952\n",
            "Epoch 187/200\n",
            "1172/1172 - 1s - loss: 0.0110 - accuracy: 0.9944\n",
            "Epoch 188/200\n",
            "1172/1172 - 1s - loss: 0.0110 - accuracy: 0.9950\n",
            "Epoch 189/200\n",
            "1172/1172 - 1s - loss: 0.0111 - accuracy: 0.9953\n",
            "Epoch 190/200\n",
            "1172/1172 - 1s - loss: 0.0115 - accuracy: 0.9949\n",
            "Epoch 191/200\n",
            "1172/1172 - 1s - loss: 0.0118 - accuracy: 0.9947\n",
            "Epoch 192/200\n",
            "1172/1172 - 1s - loss: 0.0108 - accuracy: 0.9953\n",
            "Epoch 193/200\n",
            "1172/1172 - 1s - loss: 0.0112 - accuracy: 0.9946\n",
            "Epoch 194/200\n",
            "1172/1172 - 1s - loss: 0.0103 - accuracy: 0.9949\n",
            "Epoch 195/200\n",
            "1172/1172 - 1s - loss: 0.0109 - accuracy: 0.9953\n",
            "Epoch 196/200\n",
            "1172/1172 - 1s - loss: 0.0106 - accuracy: 0.9950\n",
            "Epoch 197/200\n",
            "1172/1172 - 1s - loss: 0.0116 - accuracy: 0.9950\n",
            "Epoch 198/200\n",
            "1172/1172 - 1s - loss: 0.0113 - accuracy: 0.9950\n",
            "Epoch 199/200\n",
            "1172/1172 - 1s - loss: 0.0112 - accuracy: 0.9950\n",
            "Epoch 200/200\n",
            "1172/1172 - 1s - loss: 0.0115 - accuracy: 0.9950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f70fa9d6810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NwhFuho5co8",
        "outputId": "adb552be-df56-4529-c9af-a4dbe37d8f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 4)                 16        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 10        \n",
            "=================================================================\n",
            "Total params: 26\n",
            "Trainable params: 26\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-98b76a859872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1097\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 964\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    965\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'str'>\"})"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT9vl1h14RKd"
      },
      "source": [
        "# INSERT ML algorithm here (X_rn, y_rn) train vs test sets\n",
        "\n",
        "\n",
        "#Mc=metrics.confusion_matrix(y_rn[int(testfraction*totalN):], y_pred)\n",
        "\n",
        "#totalN=Mc[0][0] + Mc[0][1] + Mc[1][0] + Mc[1][1]\n",
        "#misclassifiedN = Mc[0][1] + Mc[1][0]\n",
        "\n",
        "#errorRate= misclassifiedN / totalN\n",
        "\n",
        "#print(\"confusion matrix: on test data set\")\n",
        "#print(Mc)\n",
        "\n",
        "#print(\"errorRate %5.3f\" % errorRate)\n",
        "print (strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "print(\"N=%d : experiment_type: %s  road_input_type: %s\" % (nruns,experiment_type, road_input_type))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}