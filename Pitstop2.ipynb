{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Pitstop2.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YV07HtF4RJf",
        "outputId": "543cbfa0-bc14-4597-eccd-eb319122a4f6"
      },
      "source": [
        "#define _FILE_SPECS \"-rw-r--r-- 1 chris 8007 Mar 25 12:33 cartsim_data.py\"\n",
        "#define _MAGIC_NUMBER 1147484068\n",
        "import numpy as np\n",
        "import math, os,   sys,  time\n",
        "from time import gmtime, strftime\n",
        "# from logger import logger\n",
        "from datetime import date, datetime, timezone\n",
        "import statistics as st\n",
        "import random as rn\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import random as rnn\n",
        " \n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "\n",
        "#equations\n",
        "# M \\ddot P = - C( X - X_0)  - D \\dot X\n",
        "#  P = X  + Z(Y(t))\n",
        "#  Y(t)= vt\n",
        "\n",
        "#  v=60km/hour = 16.666 m / sec\n",
        "#\n",
        "#  M= 1000kg\n",
        "#  X_0 =  5cm\n",
        "#  C spring const so 1000kg @ 10 m/sec^2 gives 5 cm ie\n",
        "#    =   5 x 10e-06\n",
        "#  X roughly +- 10cm\n",
        "#  road 3 components period   1 sec, 2 sec, 4 sec (random amplitude)\n",
        "#  sin(Y/(16.666)),  cos(Y/(16.666)), sin(Y/(2*16.66)), cos(Y/(2*16.66))\n",
        "#  choose D0 to efold in 1 second ie. D/2M = 1.0 --> D=2000\n",
        "#  too small is 'bad'\n",
        "#  choose sampling rate @ 4 Hz\n",
        "#  magnitude road = +- 5 max * sin( Y / 16.66 m)\n",
        "\n",
        "#  10 minute samples = 600 x 4 points @ 4 Hz\n",
        "#\n",
        "\n",
        "def Zbase ( trigtype, period, K, Y):\n",
        "    \n",
        "    if trigtype=='sin':\n",
        "        return math.sin( K * period * Y)\n",
        "    if trigtype=='cos':\n",
        "        return math.cos( K * period * Y)\n",
        "    \n",
        "def Zbaseddot ( trigtype, period, K, Y, v):\n",
        "    \n",
        "#     d^2/dt^ (VT)=0\n",
        "    if trigtype=='sin':\n",
        "        return -math.cos( K * period * Y) * v * v * (K /period) * (K/period)\n",
        "    if trigtype=='cos':\n",
        "        return -math.sin( K * period * Y) * v * v * (K /period) * (K/period)\n",
        "    \n",
        "def Xdot(Xn, Xnm1, dT):\n",
        "    return (Xn - Xnm1)/dT\n",
        "\n",
        "def Xddot(Xn, Xnm1, Xnm2, dT):\n",
        "    return (Xn - 2 * Xnm1  + Xnm2)/(dT * dT)\n",
        "\n",
        "def getXnp1(LHS, M, D, C, Xn, Xnm1, dT):\n",
        "# solve for Xnp1\n",
        "#  LHS = M(Xnp1 - 2 Xn + Xnm1)/delT^2 + D(Xnp1 - Xnm1)/2delT + C Xn\n",
        "  \n",
        "    rval = (LHS * dT * dT - (M - D * dT/2) * Xnm1  + (2 *M - C * dT * dT) * Xn  )/(M + D * dT/2) \n",
        "    \n",
        "    lv = M* (rval - 2 * Xn + Xnm1)/(dT * dT) + D* (rval - Xnm1)/(2*dT) + C * Xn\n",
        "    \n",
        "#    print(\"check %f = %f\" % (LHS,lv))\n",
        "          \n",
        "    return  rval\n",
        "\n",
        "def getLHSval(Zddval, Ms, Vs, Cs, X0s):\n",
        "# Cs * X0 =spring force\n",
        "    return - Ms * Zddval + Cs * X0s\n",
        "\n",
        "def zRoad(coeffs, v, Y, period, maxfreq):\n",
        "    \n",
        "    zR =0\n",
        "   \n",
        "    if maxfreq >= 0.5:\n",
        "       zR = coeffs[0]* Zbaseddot('cos', period, 0.5, Y, v) + zR\n",
        "       zR = coeffs[1]* Zbaseddot('sin', period, 0.5, Y, v) + zR\n",
        "\n",
        "    if maxfreq >= 1.0:\n",
        "       zR = coeffs[2]* Zbaseddot('cos', period, 1.0, Y, v) + zR\n",
        "       zR = coeffs[3]* Zbaseddot('sin', period, 1.0, Y, v) + zR\n",
        "    \n",
        "    if maxfreq >=2.0:\n",
        "       zR = coeffs[4]* Zbaseddot('cos', period, 2.0, Y, v) + zR\n",
        "       zR = coeffs[5]* Zbaseddot('sin', period, 2.0, Y, v) + zR\n",
        "       \n",
        "    if maxfreq >=4.0:\n",
        "       zR = coeffs[6]* Zbaseddot('cos', period, 4.0, Y, v) + zR\n",
        "       zR = coeffs[7]* Zbaseddot('sin', period, 4.0, Y, v) + zR\n",
        "    \n",
        "    return zR\n",
        "\n",
        "def  getRandomCoeffs(N):\n",
        "    \n",
        "     ampChoice=[0.01, 0.02, 0.025, 0.03, 0.035]\n",
        "     coeffs=[]\n",
        "\n",
        "     for i in range(0,N):\n",
        "          rAmpl1=rn.choice(ampChoice) \n",
        "#          rAmpl1=rAmpl\n",
        "          coeffs.append(rAmpl1)\n",
        "          \n",
        "     return coeffs\n",
        " \n",
        " \n",
        "\n",
        "def  compute_sim(M, D0, V, C, X0, delT, period, maxfreq, coeffs, topsample):\n",
        "    \n",
        "    Y=0\n",
        "# start with spring at rest\n",
        "    Xnp1=X0\n",
        "    Xn=X0\n",
        "    Xnm1=X0\n",
        "\n",
        "\n",
        "    springPos=[]\n",
        "    timeVal=[]\n",
        "    roadSurf=[]\n",
        "    \n",
        "     \n",
        "    for i in range(0, topsample):\n",
        "    \n",
        "        t= i * delT\n",
        "        timeVal.append(t)\n",
        "#        print(\"                T=%8.2f\" % t)\n",
        "    \n",
        "        Y= V * t  \n",
        "    \n",
        "        Zddval= zRoad(coeffs, V, Y, period, maxfreq)\n",
        "    \n",
        "#        print(\"Zddval %f\" % Zddval)\n",
        "    \n",
        "# LHS= -M (ddot (Z(Y))) + CX0\n",
        "        LHS= getLHSval(Zddval, M, V, C, X0)\n",
        "        roadSurf.append(LHS)\n",
        "    \n",
        "        Xnp1 = getXnp1(LHS, M, D0, C, Xn, Xnm1, delT)\n",
        "        springPos.append(Xnp1)\n",
        "    \n",
        "#        print(\"Xnp1 %8.3f  Xn %8.3f Xnm1 %8.3f\" % (Xnp1, Xn, Xnm1))\n",
        "    \n",
        "        Xnm1=Xn\n",
        "        Xn=Xnp1\n",
        "        \n",
        "    return [roadSurf, timeVal, springPos, t]\n",
        "\n",
        "def add_sample(M, D0, V, C, X0, delT, period, maxfreq, botsample, topsample, lval,Ncoeffs, Rcoeffs, road_input_type):\n",
        " # compute discriminant\n",
        "    disc= D0*D0 - 4 * M * C   \n",
        "    \n",
        "    [roadSurf, timeVals, springPos, tmax]= compute_sim(M, D0, V, C, X0, delT, period, maxfreq, Rcoeffs, topsample)\n",
        "\n",
        "    yval=[]\n",
        "    Xdat=[]\n",
        "\n",
        "#    print(\"sample D0=%d label=%s\" % (D0,lval )) \n",
        "#    print(\"D=%12.2f disc  %12.2f   maxfreq= %f\" % (D0, disc,   maxfreq))\n",
        "#    if disc < 0:\n",
        "#        print(\"sqrt = %f\" % math.sqrt(-disc))\n",
        " \n",
        "# assume botsample is > 3\n",
        "\n",
        "    if road_input_type=='vibration':\n",
        "        tupleLen=8\n",
        "    elif road_input_type=='surface':\n",
        "        tupleLen=2\n",
        "    else:\n",
        "        print(\"unknown road_type %s\" % road_type)\n",
        "        tupleLen=2\n",
        " \n",
        "# in this case include roadSurf = LHS as variable\n",
        "    xnorm=10000 \n",
        "    for i in range(botsample,topsample):\n",
        "        if tupleLen==2:\n",
        "# road input\n",
        "           Xdat.append([roadSurf[i]/xnorm, springPos[i-2], springPos[i-1], springPos[i]])\n",
        "# in vehicle vibration\n",
        "        elif tupleLen==5:\n",
        "           Xdat.append([springPos[i-5], springPos[i-4], springPos[i-3], springPos[i-2], springPos[i-1], springPos[i]])\n",
        "#  in vehicle vibration (long)\n",
        "        elif tupleLen==8:\n",
        "           Xdat.append([springPos[-8], springPos[-7], springPos[-6], springPos[i-5], springPos[i-4], springPos[i-3], springPos[i-2], springPos[i-1], springPos[i]])\n",
        "        else:\n",
        "            print(\"Unsupported tupleLen %d\" % tupleLen)\n",
        "            return [[],[]]\n",
        "        \n",
        "        yval.append(lval)\n",
        " \n",
        "    return [Xdat, yval]\n",
        "    \n",
        "\n",
        "# mass    \n",
        "M=2000 \n",
        "#   5cm compression\n",
        "X0= 0.05\n",
        "# spring const    \n",
        "\n",
        "C= 0.6  * 10e+04\n",
        "delT=0.25\n",
        "# interesting values 500, 5000, 15000, 25000\n",
        " \n",
        "# damping\n",
        "Dvalues=[5000, 5500, 6000, 6500, 4500, 4000, 3500, 500, 600, 700, 800, 400, 300, 200]\n",
        "\n",
        "LABELvalues=['good','good', 'good', 'good', 'good','good','good','bad','bad','bad','bad','bad','bad','bad']\n",
        "\n",
        "dindexlist=[x for x in range(0,14)]\n",
        "\n",
        " \n",
        "# car moves at 16.66 m/s\n",
        "V= 16.66 \n",
        "period= 16.66 \n",
        "maxfreq=4.0\n",
        " \n",
        "botsample=400 \n",
        "topsample=500\n",
        "Ncoeffs=8\n",
        "\n",
        "X=[]\n",
        "y=[]\n",
        "ngood=0\n",
        "nbad=0\n",
        "\n",
        "nruns=500\n",
        "testfraction=0.3\n",
        "experiment_type='random_roads'\n",
        "#experiment_type='standard_road'\n",
        "\n",
        "# initialize road\n",
        "Rcoeffs=getRandomCoeffs(Ncoeffs) \n",
        "\n",
        "ldindexlist=[x for x in range(0, 100* nruns)]\n",
        "\n",
        "for i in range(0,nruns):\n",
        "    \n",
        "           dindex=rn.choice(dindexlist)\n",
        "\n",
        "           D0=Dvalues[dindex]\n",
        "           labval=LABELvalues[dindex]\n",
        "    \n",
        " \n",
        "           if experiment_type=='random_roads':\n",
        "              Rcoeffs=getRandomCoeffs(Ncoeffs)\n",
        "              \n",
        "\n",
        " \n",
        "#  For  in vehicle vibration road_input_type='vibration'\n",
        "#  For  road input set road_input_type='surface'\n",
        "           \n",
        "           road_input_type='surface'\n",
        " \n",
        "           [Xdat, yval]= add_sample(M, D0, V, C, X0, delT, period, maxfreq, botsample, topsample, labval,Ncoeffs, Rcoeffs, road_input_type)\n",
        "           \n",
        "# [roadsurf, Xn-2, Xn-1, Xn]\n",
        "           if yval[0]=='good':\n",
        "               ngood+=1\n",
        "           if yval[0]=='bad':\n",
        "               nbad+=1\n",
        " \n",
        "           for j in range(0, len(Xdat)):\n",
        "                X.append(Xdat[j])\n",
        "                y.append(yval[j])\n",
        "                \n",
        "\n",
        "print(\"shuffling %d entries\" % len(ldindexlist))\n",
        "rn.shuffle(ldindexlist)\n",
        "# sanity check\n",
        "print(ldindexlist[0:10])\n",
        "\n",
        "X_rn=[]\n",
        "y_rn=[]\n",
        "\n",
        "for i in range(0, len(X)):\n",
        "    X_rn.append(X[ldindexlist[i]])\n",
        "    y_rn.append(y[ldindexlist[i]])\n",
        "    \n",
        "    \n",
        "           \n",
        "print(\"made %d samples with botsample %d topsample %d\" % (nruns,botsample, topsample))\n",
        "print(\"maxfreq= %8.2f M= %8.2f V=%8.2f C=%8.2f\" % (maxfreq, M, V, C))\n",
        "\n",
        "totalN=len(X)\n",
        "print(\"Total samples %d good runs %d bad runs %d\" % (totalN, ngood, nbad))\n",
        "\n",
        "#print(Xdat)\n",
        "\n",
        "print (strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        " \n",
        "\n",
        " \n",
        "    \n",
        "    \n",
        "    \n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shuffling 50000 entries\n",
            "[22424, 23263, 24069, 22766, 10163, 29433, 25754, 24058, 28799, 9486]\n",
            "made 500 samples with botsample 400 topsample 500\n",
            "maxfreq=     4.00 M=  2000.00 V=   16.66 C=60000.00\n",
            "Total samples 50000 good runs 254 bad runs 246\n",
            "2021-05-21 01:54:40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAPMBWUBqhyd"
      },
      "source": [
        "The confusion matrix is a common metric to measure the performance of a classification algorithm. In this case, only \"good\" and \"bad\" are labelled (binary). So the confusion matrix can be shown as below:\n",
        "\n",
        "|               | Predicted(No) | Predicted(Yes)  |\n",
        "| ------------- |:---------------:| -----------------:|\n",
        "| **Actual(No)**   | True Negatives (TN) | False Positives (FP) |\n",
        "| **Actual(Yes)**  | False Negatives (FN) | True Positives (TP) |\n",
        "\n",
        "From the matrix, we could get the Accuracy by this formula:\n",
        "$$ Accuracy = \\frac {TP + TN}{TP + TN + FP + FN} $$\n",
        "\n",
        "And the Error rate would be $1-Accuracy$, same as\n",
        "$$ ErrorRate = \\frac {FP + FN}{TP + TN + FP + FN} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khXusr_hwnU0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2U5I0OopZ-q"
      },
      "source": [
        "def ml_result_report(y_test, y_pred):\n",
        "  # Create Confusion Matrix with testing and prediction data\n",
        "  Mc = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  totalN = Mc[0][0] + Mc[0][1] + Mc[1][0] + Mc[1][1]\n",
        "  misclassifiedN = Mc[0][1] + Mc[1][0]\n",
        "\n",
        "  errorRate = misclassifiedN / totalN\n",
        "\n",
        "  print(\"confusion matrix: on test data set\")\n",
        "  print(Mc)\n",
        "\n",
        "  print(\"errorRate %5.3f\" % errorRate)\n",
        "  print (strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "  print(\"N=%d : experiment_type: %s  road_input_type: %s\" % (nruns,experiment_type, road_input_type))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFixtxd84RKP"
      },
      "source": [
        "# Split samples\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rn, y_rn, test_size=testfraction, random_state=42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TInQeO0k4RKS",
        "outputId": "457b6a9f-792d-4536-fab4-b45decfedead"
      },
      "source": [
        "print(len(X_train), len(y_train))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37500 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeuSiJPR4RKT",
        "outputId": "392d8989-7b5e-4aa2-ab98-1d42fa8082e9"
      },
      "source": [
        "# Standardization of sample\n",
        "X_scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "X_train_scaled"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.34739599, -0.56561797, -1.33855545, -0.74212603],\n",
              "       [ 1.62015677,  0.2460635 ,  1.87908785,  1.39094046],\n",
              "       [ 0.37701005,  1.72934617,  1.19623471, -0.49227254],\n",
              "       ...,\n",
              "       [-1.08646433, -1.68841625, -1.24535057,  0.50715179],\n",
              "       [-0.92912275, -0.17204074, -1.099883  , -0.76859575],\n",
              "       [ 0.81094154, -1.54774079, -0.5299586 ,  1.11947538]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k5MyPu74RKX",
        "outputId": "2da089cc-3ed8-465a-fe77-d0c8606d7b8e"
      },
      "source": [
        "# KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "knn.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQjq939p4RKY",
        "outputId": "477a3405-4fc8-4248-8fa0-8dbffaf8f387"
      },
      "source": [
        "knn.score(X_test_scaled, y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmHoSdJf4RKa",
        "outputId": "9ff08098-c72f-490c-e6f3-888d963dadda"
      },
      "source": [
        "knn.score(X_train_scaled, y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9902933333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onr2nqyV_pvG"
      },
      "source": [
        "y_pred_knn = knn.predict(X_test_scaled)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOWk7pGS_iP3",
        "outputId": "31a70ed5-116c-4c95-8a30-2f778a20e289",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Confusion Matrix for KNN\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred_knn)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6157,   41],\n",
              "       [ 213, 6089]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6Q1J0RQ4RKb",
        "outputId": "9e24291c-568d-4145-9ee9-a7f3a90657c8"
      },
      "source": [
        "# Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0krP1_TQ4RKb",
        "outputId": "251e848f-f4b3-4499-bd37-0b4b0f6e4d1e"
      },
      "source": [
        "rf.score(X_test_scaled, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpBPp6Xo4RKc",
        "outputId": "e402affe-9a96-4923-a446-4c7d2766b5db"
      },
      "source": [
        "knn.score(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9918133333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blXHIrju4ctv"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGNnNlIlkT49",
        "outputId": "947a6908-744c-4c72-905f-c90c0f087c4c"
      },
      "source": [
        "# Confirm the unique label values\n",
        "unique = list(dict.fromkeys(y_rn))\n",
        "unique"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bad', 'good']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJVz2eBXm0mJ"
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rn, y_rn, random_state=42)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cozq1bS8m36F",
        "outputId": "db66b269-ab61-4822-c968-00122327a461"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "X_train_scaled"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.13007432,  1.46143808,  0.04876827, -1.5330586 ],\n",
              "       [ 0.91091633, -0.80203482,  1.10820151,  1.63064832],\n",
              "       [-0.83662889,  0.40935125, -0.78275212, -1.1748913 ],\n",
              "       ...,\n",
              "       [-0.87717078, -0.17245449, -0.80578299, -0.59081935],\n",
              "       [ 0.95475532, -0.24396082,  0.86302739,  0.93560387],\n",
              "       [-1.61655609,  0.58041581, -1.53757117, -2.06746903]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCXlZZyN4RKc",
        "outputId": "01d3b56a-41c8-4444-de68-973523be86d6"
      },
      "source": [
        "# Transform y values\n",
        "label_model = LabelEncoder()\n",
        "label_model.fit(y_train)\n",
        "\n",
        "y_train_encoded = label_model.transform(y_train)\n",
        "y_test_encoded = label_model.transform(y_test)\n",
        "y_train_encoded"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlOkEr3Z4RKd",
        "outputId": "977cf04e-3c1c-4e3f-eb05-e805f2ecb713"
      },
      "source": [
        "# Convert to categorical data\n",
        "\n",
        "\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "y_test_categorical = to_categorical(y_test_encoded)\n",
        "y_train_categorical"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnH7nGel5HVc",
        "outputId": "2bbb4f6d-d0e5-465e-e73c-e2568433ad2b"
      },
      "source": [
        "# Building NN model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=4, activation=\"relu\", input_dim=4))\n",
        "model.add(Dense(units=3, activation=\"softmax\"))\n",
        "model.add(Dense(units=3, activation=\"relu\"))\n",
        "model.add(Dense(units=2, activation=\"softmax\"))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 15        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 8         \n",
            "=================================================================\n",
            "Total params: 55\n",
            "Trainable params: 55\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IerFuUz-5P5G",
        "outputId": "88dae23f-2705-4b3e-845b-cdc60fe94d35"
      },
      "source": [
        "# Fitting model\n",
        "model.fit(X_train_scaled, y_train_categorical, epochs=200, shuffle=True, verbose=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1172/1172 - 2s - loss: 0.6766 - accuracy: 0.5744\n",
            "Epoch 2/200\n",
            "1172/1172 - 1s - loss: 0.4677 - accuracy: 0.8326\n",
            "Epoch 3/200\n",
            "1172/1172 - 1s - loss: 0.3024 - accuracy: 0.8956\n",
            "Epoch 4/200\n",
            "1172/1172 - 1s - loss: 0.2655 - accuracy: 0.9034\n",
            "Epoch 5/200\n",
            "1172/1172 - 1s - loss: 0.2525 - accuracy: 0.9054\n",
            "Epoch 6/200\n",
            "1172/1172 - 1s - loss: 0.2456 - accuracy: 0.9062\n",
            "Epoch 7/200\n",
            "1172/1172 - 1s - loss: 0.2411 - accuracy: 0.9067\n",
            "Epoch 8/200\n",
            "1172/1172 - 1s - loss: 0.2376 - accuracy: 0.9075\n",
            "Epoch 9/200\n",
            "1172/1172 - 1s - loss: 0.2350 - accuracy: 0.9072\n",
            "Epoch 10/200\n",
            "1172/1172 - 1s - loss: 0.2324 - accuracy: 0.9088\n",
            "Epoch 11/200\n",
            "1172/1172 - 1s - loss: 0.2302 - accuracy: 0.9097\n",
            "Epoch 12/200\n",
            "1172/1172 - 1s - loss: 0.2283 - accuracy: 0.9106\n",
            "Epoch 13/200\n",
            "1172/1172 - 1s - loss: 0.2261 - accuracy: 0.9109\n",
            "Epoch 14/200\n",
            "1172/1172 - 1s - loss: 0.2242 - accuracy: 0.9109\n",
            "Epoch 15/200\n",
            "1172/1172 - 1s - loss: 0.2233 - accuracy: 0.9116\n",
            "Epoch 16/200\n",
            "1172/1172 - 1s - loss: 0.2216 - accuracy: 0.9119\n",
            "Epoch 17/200\n",
            "1172/1172 - 1s - loss: 0.2202 - accuracy: 0.9123\n",
            "Epoch 18/200\n",
            "1172/1172 - 1s - loss: 0.2191 - accuracy: 0.9130\n",
            "Epoch 19/200\n",
            "1172/1172 - 1s - loss: 0.2173 - accuracy: 0.9141\n",
            "Epoch 20/200\n",
            "1172/1172 - 1s - loss: 0.2160 - accuracy: 0.9144\n",
            "Epoch 21/200\n",
            "1172/1172 - 1s - loss: 0.2151 - accuracy: 0.9143\n",
            "Epoch 22/200\n",
            "1172/1172 - 1s - loss: 0.2142 - accuracy: 0.9159\n",
            "Epoch 23/200\n",
            "1172/1172 - 1s - loss: 0.2126 - accuracy: 0.9158\n",
            "Epoch 24/200\n",
            "1172/1172 - 1s - loss: 0.2118 - accuracy: 0.9164\n",
            "Epoch 25/200\n",
            "1172/1172 - 1s - loss: 0.2106 - accuracy: 0.9177\n",
            "Epoch 26/200\n",
            "1172/1172 - 1s - loss: 0.2092 - accuracy: 0.9178\n",
            "Epoch 27/200\n",
            "1172/1172 - 1s - loss: 0.2081 - accuracy: 0.9184\n",
            "Epoch 28/200\n",
            "1172/1172 - 1s - loss: 0.2074 - accuracy: 0.9186\n",
            "Epoch 29/200\n",
            "1172/1172 - 1s - loss: 0.2061 - accuracy: 0.9200\n",
            "Epoch 30/200\n",
            "1172/1172 - 1s - loss: 0.2048 - accuracy: 0.9210\n",
            "Epoch 31/200\n",
            "1172/1172 - 1s - loss: 0.2038 - accuracy: 0.9218\n",
            "Epoch 32/200\n",
            "1172/1172 - 1s - loss: 0.2022 - accuracy: 0.9223\n",
            "Epoch 33/200\n",
            "1172/1172 - 1s - loss: 0.2009 - accuracy: 0.9240\n",
            "Epoch 34/200\n",
            "1172/1172 - 1s - loss: 0.1999 - accuracy: 0.9230\n",
            "Epoch 35/200\n",
            "1172/1172 - 1s - loss: 0.1990 - accuracy: 0.9245\n",
            "Epoch 36/200\n",
            "1172/1172 - 1s - loss: 0.1980 - accuracy: 0.9251\n",
            "Epoch 37/200\n",
            "1172/1172 - 1s - loss: 0.1976 - accuracy: 0.9245\n",
            "Epoch 38/200\n",
            "1172/1172 - 1s - loss: 0.1968 - accuracy: 0.9249\n",
            "Epoch 39/200\n",
            "1172/1172 - 1s - loss: 0.1960 - accuracy: 0.9253\n",
            "Epoch 40/200\n",
            "1172/1172 - 1s - loss: 0.1957 - accuracy: 0.9253\n",
            "Epoch 41/200\n",
            "1172/1172 - 1s - loss: 0.1954 - accuracy: 0.9257\n",
            "Epoch 42/200\n",
            "1172/1172 - 1s - loss: 0.1945 - accuracy: 0.9259\n",
            "Epoch 43/200\n",
            "1172/1172 - 1s - loss: 0.1943 - accuracy: 0.9265\n",
            "Epoch 44/200\n",
            "1172/1172 - 1s - loss: 0.1937 - accuracy: 0.9259\n",
            "Epoch 45/200\n",
            "1172/1172 - 1s - loss: 0.1936 - accuracy: 0.9272\n",
            "Epoch 46/200\n",
            "1172/1172 - 1s - loss: 0.1931 - accuracy: 0.9263\n",
            "Epoch 47/200\n",
            "1172/1172 - 1s - loss: 0.1927 - accuracy: 0.9266\n",
            "Epoch 48/200\n",
            "1172/1172 - 1s - loss: 0.1929 - accuracy: 0.9275\n",
            "Epoch 49/200\n",
            "1172/1172 - 1s - loss: 0.1919 - accuracy: 0.9275\n",
            "Epoch 50/200\n",
            "1172/1172 - 1s - loss: 0.1918 - accuracy: 0.9277\n",
            "Epoch 51/200\n",
            "1172/1172 - 1s - loss: 0.1916 - accuracy: 0.9281\n",
            "Epoch 52/200\n",
            "1172/1172 - 1s - loss: 0.1913 - accuracy: 0.9278\n",
            "Epoch 53/200\n",
            "1172/1172 - 1s - loss: 0.1910 - accuracy: 0.9273\n",
            "Epoch 54/200\n",
            "1172/1172 - 1s - loss: 0.1909 - accuracy: 0.9285\n",
            "Epoch 55/200\n",
            "1172/1172 - 1s - loss: 0.1905 - accuracy: 0.9279\n",
            "Epoch 56/200\n",
            "1172/1172 - 1s - loss: 0.1904 - accuracy: 0.9277\n",
            "Epoch 57/200\n",
            "1172/1172 - 1s - loss: 0.1904 - accuracy: 0.9277\n",
            "Epoch 58/200\n",
            "1172/1172 - 1s - loss: 0.1905 - accuracy: 0.9290\n",
            "Epoch 59/200\n",
            "1172/1172 - 1s - loss: 0.1899 - accuracy: 0.9283\n",
            "Epoch 60/200\n",
            "1172/1172 - 1s - loss: 0.1897 - accuracy: 0.9286\n",
            "Epoch 61/200\n",
            "1172/1172 - 1s - loss: 0.1894 - accuracy: 0.9285\n",
            "Epoch 62/200\n",
            "1172/1172 - 1s - loss: 0.1896 - accuracy: 0.9283\n",
            "Epoch 63/200\n",
            "1172/1172 - 1s - loss: 0.1894 - accuracy: 0.9289\n",
            "Epoch 64/200\n",
            "1172/1172 - 1s - loss: 0.1892 - accuracy: 0.9289\n",
            "Epoch 65/200\n",
            "1172/1172 - 1s - loss: 0.1892 - accuracy: 0.9280\n",
            "Epoch 66/200\n",
            "1172/1172 - 1s - loss: 0.1889 - accuracy: 0.9288\n",
            "Epoch 67/200\n",
            "1172/1172 - 1s - loss: 0.1883 - accuracy: 0.9293\n",
            "Epoch 68/200\n",
            "1172/1172 - 1s - loss: 0.1885 - accuracy: 0.9289\n",
            "Epoch 69/200\n",
            "1172/1172 - 1s - loss: 0.1889 - accuracy: 0.9285\n",
            "Epoch 70/200\n",
            "1172/1172 - 1s - loss: 0.1882 - accuracy: 0.9294\n",
            "Epoch 71/200\n",
            "1172/1172 - 1s - loss: 0.1884 - accuracy: 0.9290\n",
            "Epoch 72/200\n",
            "1172/1172 - 1s - loss: 0.1878 - accuracy: 0.9301\n",
            "Epoch 73/200\n",
            "1172/1172 - 1s - loss: 0.1883 - accuracy: 0.9286\n",
            "Epoch 74/200\n",
            "1172/1172 - 1s - loss: 0.1877 - accuracy: 0.9291\n",
            "Epoch 75/200\n",
            "1172/1172 - 1s - loss: 0.1876 - accuracy: 0.9295\n",
            "Epoch 76/200\n",
            "1172/1172 - 1s - loss: 0.1879 - accuracy: 0.9292\n",
            "Epoch 77/200\n",
            "1172/1172 - 1s - loss: 0.1873 - accuracy: 0.9297\n",
            "Epoch 78/200\n",
            "1172/1172 - 1s - loss: 0.1874 - accuracy: 0.9289\n",
            "Epoch 79/200\n",
            "1172/1172 - 1s - loss: 0.1873 - accuracy: 0.9296\n",
            "Epoch 80/200\n",
            "1172/1172 - 1s - loss: 0.1870 - accuracy: 0.9297\n",
            "Epoch 81/200\n",
            "1172/1172 - 1s - loss: 0.1874 - accuracy: 0.9295\n",
            "Epoch 82/200\n",
            "1172/1172 - 1s - loss: 0.1870 - accuracy: 0.9294\n",
            "Epoch 83/200\n",
            "1172/1172 - 1s - loss: 0.1873 - accuracy: 0.9292\n",
            "Epoch 84/200\n",
            "1172/1172 - 1s - loss: 0.1867 - accuracy: 0.9301\n",
            "Epoch 85/200\n",
            "1172/1172 - 1s - loss: 0.1865 - accuracy: 0.9299\n",
            "Epoch 86/200\n",
            "1172/1172 - 1s - loss: 0.1867 - accuracy: 0.9293\n",
            "Epoch 87/200\n",
            "1172/1172 - 1s - loss: 0.1867 - accuracy: 0.9297\n",
            "Epoch 88/200\n",
            "1172/1172 - 1s - loss: 0.1866 - accuracy: 0.9304\n",
            "Epoch 89/200\n",
            "1172/1172 - 1s - loss: 0.1868 - accuracy: 0.9300\n",
            "Epoch 90/200\n",
            "1172/1172 - 1s - loss: 0.1868 - accuracy: 0.9299\n",
            "Epoch 91/200\n",
            "1172/1172 - 1s - loss: 0.1867 - accuracy: 0.9294\n",
            "Epoch 92/200\n",
            "1172/1172 - 1s - loss: 0.1861 - accuracy: 0.9292\n",
            "Epoch 93/200\n",
            "1172/1172 - 1s - loss: 0.1864 - accuracy: 0.9297\n",
            "Epoch 94/200\n",
            "1172/1172 - 1s - loss: 0.1866 - accuracy: 0.9296\n",
            "Epoch 95/200\n",
            "1172/1172 - 1s - loss: 0.1858 - accuracy: 0.9296\n",
            "Epoch 96/200\n",
            "1172/1172 - 1s - loss: 0.1860 - accuracy: 0.9303\n",
            "Epoch 97/200\n",
            "1172/1172 - 1s - loss: 0.1861 - accuracy: 0.9302\n",
            "Epoch 98/200\n",
            "1172/1172 - 1s - loss: 0.1859 - accuracy: 0.9300\n",
            "Epoch 99/200\n",
            "1172/1172 - 1s - loss: 0.1858 - accuracy: 0.9296\n",
            "Epoch 100/200\n",
            "1172/1172 - 1s - loss: 0.1857 - accuracy: 0.9307\n",
            "Epoch 101/200\n",
            "1172/1172 - 1s - loss: 0.1852 - accuracy: 0.9304\n",
            "Epoch 102/200\n",
            "1172/1172 - 1s - loss: 0.1856 - accuracy: 0.9303\n",
            "Epoch 103/200\n",
            "1172/1172 - 1s - loss: 0.1852 - accuracy: 0.9299\n",
            "Epoch 104/200\n",
            "1172/1172 - 1s - loss: 0.1860 - accuracy: 0.9298\n",
            "Epoch 105/200\n",
            "1172/1172 - 1s - loss: 0.1856 - accuracy: 0.9299\n",
            "Epoch 106/200\n",
            "1172/1172 - 1s - loss: 0.1855 - accuracy: 0.9301\n",
            "Epoch 107/200\n",
            "1172/1172 - 1s - loss: 0.1858 - accuracy: 0.9298\n",
            "Epoch 108/200\n",
            "1172/1172 - 1s - loss: 0.1854 - accuracy: 0.9301\n",
            "Epoch 109/200\n",
            "1172/1172 - 1s - loss: 0.1854 - accuracy: 0.9302\n",
            "Epoch 110/200\n",
            "1172/1172 - 1s - loss: 0.1852 - accuracy: 0.9305\n",
            "Epoch 111/200\n",
            "1172/1172 - 1s - loss: 0.1856 - accuracy: 0.9297\n",
            "Epoch 112/200\n",
            "1172/1172 - 1s - loss: 0.1856 - accuracy: 0.9299\n",
            "Epoch 113/200\n",
            "1172/1172 - 1s - loss: 0.1849 - accuracy: 0.9297\n",
            "Epoch 114/200\n",
            "1172/1172 - 1s - loss: 0.1849 - accuracy: 0.9307\n",
            "Epoch 115/200\n",
            "1172/1172 - 1s - loss: 0.1851 - accuracy: 0.9301\n",
            "Epoch 116/200\n",
            "1172/1172 - 1s - loss: 0.1849 - accuracy: 0.9303\n",
            "Epoch 117/200\n",
            "1172/1172 - 1s - loss: 0.1846 - accuracy: 0.9301\n",
            "Epoch 118/200\n",
            "1172/1172 - 1s - loss: 0.1848 - accuracy: 0.9303\n",
            "Epoch 119/200\n",
            "1172/1172 - 1s - loss: 0.1846 - accuracy: 0.9304\n",
            "Epoch 120/200\n",
            "1172/1172 - 1s - loss: 0.1850 - accuracy: 0.9307\n",
            "Epoch 121/200\n",
            "1172/1172 - 1s - loss: 0.1846 - accuracy: 0.9306\n",
            "Epoch 122/200\n",
            "1172/1172 - 1s - loss: 0.1844 - accuracy: 0.9304\n",
            "Epoch 123/200\n",
            "1172/1172 - 1s - loss: 0.1844 - accuracy: 0.9302\n",
            "Epoch 124/200\n",
            "1172/1172 - 1s - loss: 0.1842 - accuracy: 0.9311\n",
            "Epoch 125/200\n",
            "1172/1172 - 1s - loss: 0.1841 - accuracy: 0.9314\n",
            "Epoch 126/200\n",
            "1172/1172 - 1s - loss: 0.1846 - accuracy: 0.9308\n",
            "Epoch 127/200\n",
            "1172/1172 - 1s - loss: 0.1843 - accuracy: 0.9303\n",
            "Epoch 128/200\n",
            "1172/1172 - 1s - loss: 0.1840 - accuracy: 0.9305\n",
            "Epoch 129/200\n",
            "1172/1172 - 1s - loss: 0.1844 - accuracy: 0.9305\n",
            "Epoch 130/200\n",
            "1172/1172 - 1s - loss: 0.1839 - accuracy: 0.9307\n",
            "Epoch 131/200\n",
            "1172/1172 - 1s - loss: 0.1845 - accuracy: 0.9305\n",
            "Epoch 132/200\n",
            "1172/1172 - 1s - loss: 0.1841 - accuracy: 0.9318\n",
            "Epoch 133/200\n",
            "1172/1172 - 1s - loss: 0.1838 - accuracy: 0.9311\n",
            "Epoch 134/200\n",
            "1172/1172 - 1s - loss: 0.1839 - accuracy: 0.9308\n",
            "Epoch 135/200\n",
            "1172/1172 - 1s - loss: 0.1839 - accuracy: 0.9306\n",
            "Epoch 136/200\n",
            "1172/1172 - 1s - loss: 0.1838 - accuracy: 0.9307\n",
            "Epoch 137/200\n",
            "1172/1172 - 1s - loss: 0.1837 - accuracy: 0.9311\n",
            "Epoch 138/200\n",
            "1172/1172 - 1s - loss: 0.1838 - accuracy: 0.9312\n",
            "Epoch 139/200\n",
            "1172/1172 - 1s - loss: 0.1839 - accuracy: 0.9314\n",
            "Epoch 140/200\n",
            "1172/1172 - 1s - loss: 0.1836 - accuracy: 0.9313\n",
            "Epoch 141/200\n",
            "1172/1172 - 1s - loss: 0.1835 - accuracy: 0.9304\n",
            "Epoch 142/200\n",
            "1172/1172 - 1s - loss: 0.1841 - accuracy: 0.9311\n",
            "Epoch 143/200\n",
            "1172/1172 - 1s - loss: 0.1836 - accuracy: 0.9313\n",
            "Epoch 144/200\n",
            "1172/1172 - 1s - loss: 0.1831 - accuracy: 0.9316\n",
            "Epoch 145/200\n",
            "1172/1172 - 1s - loss: 0.1840 - accuracy: 0.9309\n",
            "Epoch 146/200\n",
            "1172/1172 - 1s - loss: 0.1833 - accuracy: 0.9318\n",
            "Epoch 147/200\n",
            "1172/1172 - 1s - loss: 0.1834 - accuracy: 0.9317\n",
            "Epoch 148/200\n",
            "1172/1172 - 1s - loss: 0.1834 - accuracy: 0.9321\n",
            "Epoch 149/200\n",
            "1172/1172 - 1s - loss: 0.1836 - accuracy: 0.9307\n",
            "Epoch 150/200\n",
            "1172/1172 - 1s - loss: 0.1836 - accuracy: 0.9310\n",
            "Epoch 151/200\n",
            "1172/1172 - 1s - loss: 0.1831 - accuracy: 0.9317\n",
            "Epoch 152/200\n",
            "1172/1172 - 1s - loss: 0.1835 - accuracy: 0.9318\n",
            "Epoch 153/200\n",
            "1172/1172 - 1s - loss: 0.1829 - accuracy: 0.9315\n",
            "Epoch 154/200\n",
            "1172/1172 - 1s - loss: 0.1833 - accuracy: 0.9313\n",
            "Epoch 155/200\n",
            "1172/1172 - 1s - loss: 0.1830 - accuracy: 0.9311\n",
            "Epoch 156/200\n",
            "1172/1172 - 1s - loss: 0.1829 - accuracy: 0.9318\n",
            "Epoch 157/200\n",
            "1172/1172 - 1s - loss: 0.1824 - accuracy: 0.9321\n",
            "Epoch 158/200\n",
            "1172/1172 - 1s - loss: 0.1832 - accuracy: 0.9315\n",
            "Epoch 159/200\n",
            "1172/1172 - 1s - loss: 0.1827 - accuracy: 0.9322\n",
            "Epoch 160/200\n",
            "1172/1172 - 1s - loss: 0.1829 - accuracy: 0.9320\n",
            "Epoch 161/200\n",
            "1172/1172 - 1s - loss: 0.1828 - accuracy: 0.9321\n",
            "Epoch 162/200\n",
            "1172/1172 - 1s - loss: 0.1830 - accuracy: 0.9323\n",
            "Epoch 163/200\n",
            "1172/1172 - 1s - loss: 0.1827 - accuracy: 0.9323\n",
            "Epoch 164/200\n",
            "1172/1172 - 1s - loss: 0.1826 - accuracy: 0.9326\n",
            "Epoch 165/200\n",
            "1172/1172 - 1s - loss: 0.1827 - accuracy: 0.9322\n",
            "Epoch 166/200\n",
            "1172/1172 - 1s - loss: 0.1822 - accuracy: 0.9324\n",
            "Epoch 167/200\n",
            "1172/1172 - 1s - loss: 0.1826 - accuracy: 0.9317\n",
            "Epoch 168/200\n",
            "1172/1172 - 1s - loss: 0.1825 - accuracy: 0.9321\n",
            "Epoch 169/200\n",
            "1172/1172 - 1s - loss: 0.1822 - accuracy: 0.9321\n",
            "Epoch 170/200\n",
            "1172/1172 - 1s - loss: 0.1825 - accuracy: 0.9323\n",
            "Epoch 171/200\n",
            "1172/1172 - 1s - loss: 0.1827 - accuracy: 0.9321\n",
            "Epoch 172/200\n",
            "1172/1172 - 1s - loss: 0.1819 - accuracy: 0.9319\n",
            "Epoch 173/200\n",
            "1172/1172 - 1s - loss: 0.1825 - accuracy: 0.9322\n",
            "Epoch 174/200\n",
            "1172/1172 - 1s - loss: 0.1824 - accuracy: 0.9323\n",
            "Epoch 175/200\n",
            "1172/1172 - 1s - loss: 0.1822 - accuracy: 0.9321\n",
            "Epoch 176/200\n",
            "1172/1172 - 1s - loss: 0.1825 - accuracy: 0.9322\n",
            "Epoch 177/200\n",
            "1172/1172 - 1s - loss: 0.1820 - accuracy: 0.9322\n",
            "Epoch 178/200\n",
            "1172/1172 - 1s - loss: 0.1817 - accuracy: 0.9325\n",
            "Epoch 179/200\n",
            "1172/1172 - 1s - loss: 0.1823 - accuracy: 0.9322\n",
            "Epoch 180/200\n",
            "1172/1172 - 1s - loss: 0.1819 - accuracy: 0.9325\n",
            "Epoch 181/200\n",
            "1172/1172 - 1s - loss: 0.1823 - accuracy: 0.9324\n",
            "Epoch 182/200\n",
            "1172/1172 - 1s - loss: 0.1816 - accuracy: 0.9324\n",
            "Epoch 183/200\n",
            "1172/1172 - 1s - loss: 0.1823 - accuracy: 0.9323\n",
            "Epoch 184/200\n",
            "1172/1172 - 1s - loss: 0.1813 - accuracy: 0.9329\n",
            "Epoch 185/200\n",
            "1172/1172 - 1s - loss: 0.1818 - accuracy: 0.9328\n",
            "Epoch 186/200\n",
            "1172/1172 - 1s - loss: 0.1820 - accuracy: 0.9324\n",
            "Epoch 187/200\n",
            "1172/1172 - 1s - loss: 0.1817 - accuracy: 0.9326\n",
            "Epoch 188/200\n",
            "1172/1172 - 1s - loss: 0.1818 - accuracy: 0.9331\n",
            "Epoch 189/200\n",
            "1172/1172 - 1s - loss: 0.1814 - accuracy: 0.9336\n",
            "Epoch 190/200\n",
            "1172/1172 - 1s - loss: 0.1818 - accuracy: 0.9328\n",
            "Epoch 191/200\n",
            "1172/1172 - 1s - loss: 0.1819 - accuracy: 0.9325\n",
            "Epoch 192/200\n",
            "1172/1172 - 1s - loss: 0.1819 - accuracy: 0.9328\n",
            "Epoch 193/200\n",
            "1172/1172 - 1s - loss: 0.1817 - accuracy: 0.9329\n",
            "Epoch 194/200\n",
            "1172/1172 - 1s - loss: 0.1814 - accuracy: 0.9325\n",
            "Epoch 195/200\n",
            "1172/1172 - 1s - loss: 0.1819 - accuracy: 0.9325\n",
            "Epoch 196/200\n",
            "1172/1172 - 1s - loss: 0.1815 - accuracy: 0.9332\n",
            "Epoch 197/200\n",
            "1172/1172 - 1s - loss: 0.1813 - accuracy: 0.9335\n",
            "Epoch 198/200\n",
            "1172/1172 - 1s - loss: 0.1817 - accuracy: 0.9323\n",
            "Epoch 199/200\n",
            "1172/1172 - 1s - loss: 0.1817 - accuracy: 0.9325\n",
            "Epoch 200/200\n",
            "1172/1172 - 1s - loss: 0.1813 - accuracy: 0.9333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f278f102f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NwhFuho5co8",
        "outputId": "c003fb4c-503a-49ae-d1a0-69b5928c25b6"
      },
      "source": [
        "# Evaluate the model\n",
        "model.evaluate(X_test_scaled, y_test_categorical, verbose=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 - 0s - loss: 0.1747 - accuracy: 0.9371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1746901422739029, 0.9371200203895569]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roGnCDz6tmBF",
        "outputId": "d6ea44af-4232-4c2c-c246-0d8867d08618",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.1878762e-02, 9.6812123e-01],\n",
              "       [9.9986744e-01, 1.3251600e-04],\n",
              "       [9.9992764e-01, 7.2340452e-05],\n",
              "       ...,\n",
              "       [9.9997902e-01, 2.0987820e-05],\n",
              "       [9.5381355e-01, 4.6186473e-02],\n",
              "       [9.9999142e-01, 8.5676775e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no3J6Eg5t1OA",
        "outputId": "cb91685a-4866-4889-de1a-1bc11f86f75d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "confusion_matrix(y_test_categorical.argmax(axis=1), y_pred.argmax(axis=1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5526,  590],\n",
              "       [ 196, 6188]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT9vl1h14RKd"
      },
      "source": [
        "# INSERT ML algorithm here (X_rn, y_rn) train vs test sets\n",
        "\n",
        "\n",
        "#Mc=metrics.confusion_matrix(y_rn[int(testfraction*totalN):], y_pred)\n",
        "\n",
        "#totalN=Mc[0][0] + Mc[0][1] + Mc[1][0] + Mc[1][1]\n",
        "#misclassifiedN = Mc[0][1] + Mc[1][0]\n",
        "\n",
        "#errorRate= misclassifiedN / totalN\n",
        "\n",
        "#print(\"confusion matrix: on test data set\")\n",
        "#print(Mc)\n",
        "\n",
        "#print(\"errorRate %5.3f\" % errorRate)\n",
        "print (strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
        "print(\"N=%d : experiment_type: %s  road_input_type: %s\" % (nruns,experiment_type, road_input_type))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}